{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb84658-0501-4dbb-a3b3-a57da2100256",
   "metadata": {},
   "source": [
    "# <div align=\"center\">  **ARDSFlag: An NLP/Machine Learning Algorithm to Visualize and Detect High-Probability ARDS Admissions Independent of Provider Recognition and Billing Codes**\n",
    "\n",
    "## <div align=\"center\"> **Gandomi et al. 2024**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ceeba-f50b-49c0-a901-030b6cf832f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Here is the list of all functions developed and used for this study:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d06ea-1844-49e0-977e-f8383bd32b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "db_connection_str = 'mysql+pymysql://root:root@localhost/mimic'\n",
    "connection = create_engine(db_connection_str)\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "lab_item_dict = {50817:'SaO2_lab',    \n",
    "                 50816:'FiO2_lab',    \n",
    "                 50821:'PaO2_lab',    \n",
    "                 50818:'PaCO2_lab',   \n",
    "                 50820: 'PH_lab'      \n",
    "                  }\n",
    "chart_item_dict = {444:'Mean_Airway_P', 224697: 'Mean_Airway_P',\n",
    "                   535:'Peak',          224695: 'Peak',\n",
    "                   505:'PEEP',          506:    'PEEP',   220339: 'PEEP',\n",
    "                   543:'Plateau_P',     224696:'Plateau_P',\n",
    "                   682:'TV_Obsed',      224685:'TV_Obsed',\n",
    "                   683:'TV_Set',        224684:'TV_Set',\n",
    "                   684:'TV_Spont',      224686:'TV_Spont',\n",
    "                   615:'RR_Total',      224690:'RR_Total',\n",
    "                   618:'RR',            220210:'RR',\n",
    "                   619:'RR_Set',        224688:'RR_Set',\n",
    "                   614:'RR_Spont',      224689:'RR_Spont',\n",
    "                   722:'Vent_Type',     223848:'Vent_Type',\n",
    "                   720:'Vent_Mode',     223849:'Vent_Mode',\n",
    "                   646:'SpO2',          220277:'SpO2',\n",
    "                   834:'SaO2_chart',    220227:'SaO2_chart',\n",
    "                   190:'FiO2_decimal_chart',\n",
    "                   3420:'FiO2_percent_chart',   223835:'FiO2_percent_chart',\n",
    "                   779:'PaO2_chart',    220224:'PaO2_chart',\n",
    "                   778:'PaCO2_chart',   220235:'PaCO2_chart',\n",
    "                   780:'PH_chart',      223830:'PH_chart',\n",
    "                   470:'O2_Flow',       223834:'O2_Flow',\n",
    "                   467:'O2_Device',     226732:'O2_Device',\n",
    "                   468:'O2_Device2',\n",
    "                   471:'O2_Flow2'\n",
    "                      }\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def text_cleaner(text):\n",
    "    import re\n",
    "    cleaned_text = text.replace(\"\\r\", \" \")\n",
    "    cleaned_text = cleaned_text.replace(\"\\n\", \" \")\n",
    "    cleaned_text = re.sub(r'[\\s]{2,}', ' ',cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*[\\d-]+\\*\\*\\]', \"2020-04-15\",cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,10}hospital.{0,10}\\*\\*\\]', \"HospitalName\",cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,10}doctor last.{0,10}[ -]scale', \"grayscale\",cleaned_text, flags=re.IGNORECASE)          #[**Doctor Last Name **] scale, color and Doppler son[**Name (NI) 14**] of bilateral\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,10}doctor last.{0,10}[ -]white', \"gray-white matter\",cleaned_text, flags=re.IGNORECASE)  # Doppler son[**Name (NI) **] was\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,10}doctor last.{0,10}[ -]matter', \"white matter\",cleaned_text, flags=re.IGNORECASE)      #Example: parietal [**Doctor Last Name 34**] matter \n",
    "    cleaned_text = re.sub(r'son\\[\\*\\*.{0,10}\\*\\*\\]', \"sonography\",cleaned_text, flags=re.IGNORECASE)         #Doppler son[**Name (NI) **] was\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,10}doctor.{0,10}\\*\\*\\]', \"DoctorName\",cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,5}doctor first name.{0,5}\\*\\*\\]', \"DoctorName\",cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,5}doctor last name.{0,5}\\*\\*\\]', \"DoctorName\",cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'\\[\\*\\*.{0,10}name.{0,10}\\*\\*\\]', \"OtherName\",cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text = re.sub(r'[_]+', ' ',cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('congestive heart failure','chf', cleaned_text,         flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('heart failure','heartfailure',   cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(fluid overload|volume overload)','fluidoverload', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('cardiac arrest','cardiacarrest', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\br[/\\s]{0,1}o\\b|rule out)','ruleout', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\bh[/\\s]{0,1}o\\b|history of)','historyof', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bvs\\.', 'versus',                cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bvs\\b', 'versus',                cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\beval\\b','evaluate',               cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('left ventricular systolic dysfunction', 'lvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('right ventricular systolic dysfunction','rvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('lv systolic dysfunction','lvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('rv systolic dysfunction','rvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('left ventricular diastolic dysfunction', 'lvddysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('right ventricular diastolic dysfunction','rvddysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('lv diastolic dysfunction','lvddysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('rv diastolic dysfunction','rvddysfunction', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('left ventricular','leftventricular', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('right ventricular','rightventricular', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blv\\b','leftventricular',  cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'\\brv\\b','rightventricular', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'acute[\\s\\S]{1,3}respiratory[\\s\\S]{1,3}distress[\\s\\S]{1,3}syndrome','ards', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'adult[\\s\\S]{1,3}respiratory[\\s\\S]{1,3}distress[\\s\\S]{1,3}syndrome','ards', cleaned_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    cleaned_text =  re.sub(r'\\brll\\b','rightlowerlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blll\\b','leftlowerlobe', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,3}lower[\\s\\S]{1,3}lobe','rightlowerlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,3}lower[\\s\\S]{1,3}lobe','leftlowerlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\brul\\b','rightupperlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blul\\b','leftupperlobe', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,3}upper[\\s\\S]{1,3}lobe','rightupperlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,3}upper[\\s\\S]{1,3}lobe', 'leftupperlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'lower[\\s\\S]{1,3}lobe','lowerlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'upper[\\s\\S]{1,3}lobe','upperlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\brml\\b','rightmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blml\\b','leftmiddlelobe', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,3}(middle|mid)[\\s\\S]{1,3}lobe','rightmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,3}(middle|mid)[\\s\\S]{1,3}lobe', 'leftmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,3}(middle|mid)[\\s\\S]{1,3}lung','rightmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,3}(middle|mid)[\\s\\S]{1,3}lung', 'leftmiddlelobe', cleaned_text, flags=re.IGNORECASE)   \n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,3}(middle|mid)[\\s\\S]{1,3}zone','rightmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,3}(middle|mid)[\\s\\S]{1,3}zone', 'leftmiddlelobe', cleaned_text, flags=re.IGNORECASE)  \n",
    "    cleaned_text =  re.sub(r'(\\b(middle|mid) right\\b|\\bright (middle|mid)\\b)', 'rightmid', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\b(middle|mid) left\\b|\\bleft (middle|mid)\\b)', 'leftmid', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right lung', 'rightlung', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left lung',  'leftlung', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right lobe', 'rightlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left lobe' , 'leftlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,2}sided' , 'leftsided', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,2}sided' , 'rightsided', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,3}upper','rightupper', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,3}upper', 'leftupper', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{1,3}lower','rightlower', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{1,3}lower', 'leftlower', cleaned_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    cleaned_text =  re.sub(r'ground[\\s\\S]{1,3}glass', 'groundglass', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'air[\\s\\S]{1,3}space[\\s\\S]{1,3}disease', 'airspacedisease', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'air[\\s\\S]{1,3}space', 'airspace', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bpna\\b', 'pneumonia', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\bs[\\s/]{0,1}p\\b|status post)', 'statuspost', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bpna\\b', 'pneumonia', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bpls\\b', 'please', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'clip[\\s\\S]{0,6}clip', 'clip', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'clip[\\s\\S]{0,2}number', 'clipnumber', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'clipnumber[\\s\\S]{0,2}\\(radiology\\)', 'clipnumber', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'reason for this examination', 'reasonforthisexamination', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'chest[\\s\\S]{0,2}portable[\\s\\S]{0,2}ap', 'chestportableap', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'medical[\\s\\S]{0,2}condition', 'medicalcondition', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('pulmonary edema', 'pulmonaryedema', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('consistent with', 'consistentwith', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'ill[\\s\\S]{0,1}defined', 'illdefined', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('final report', 'finalreport', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('no chf', 'nochf', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('admitting diagnos', 'admittingdiagnos', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\bcad\\b|coronary artery disease)', 'coronaryarterydisease', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\br lung\\b', 'rightlung', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bl lung\\b', 'leftlung', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(unchanged|not changed)', 'notchanged', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('pleural effusion', 'pleuraleffusion', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('most likely', 'mostlikely', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('probably', 'likely', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(campared to|in comparison with)', 'camparedto', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('no other', 'noother', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\bet tube\\b|\\bett\\b|endotracheal tube)', 'ett', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('alveolar opac', 'alveolaropac', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('interstitial opac', 'interstitialopac', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('parenchymal opac', 'parenchymalopac', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'year[\\s\\S]{0,2}old[\\s\\S]{0,2}man', 'yearoldman', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'year[\\s\\S]{0,2}old[\\s\\S]{0,2}woman', 'yearoldwoman', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'years[\\s\\S]{0,2}old', 'yearsold', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'heart[\\s\\S]{0,3}size', 'heartsize', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'cardiogenic shock', 'cardiogenicshock', cleaned_text, flags=re.IGNORECASE) \n",
    "    return cleaned_text\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def sentence_tokenizer(row):\n",
    "    from nltk import sent_tokenize\n",
    "    sentences = sent_tokenize(row)\n",
    "    \n",
    "#     punctuation_signs = list(\"!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~\")\n",
    "#     cleaned_sentences = [''.join([letter for letter in sentence if letter not in punctuation_signs]) for sentence in sentences]\n",
    "    return sentences\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def ML_sentence_scorer(row,classifier):\n",
    "    import numpy as np\n",
    "    positive_sentences = [sentence for sentence in row if classifier.predict([sentence])[0] ==1] \n",
    "    # To handle: AttributeError: probability estimates are not available for loss='hinge'\n",
    "    try: \n",
    "        positive_sentence_scores = [classifier.predict_proba([sentence])[0][1] for sentence in positive_sentences]\n",
    "    except AttributeError:\n",
    "        positive_sentence_scores = [np.NaN for sentence in positive_sentences]\n",
    "    return (positive_sentences,positive_sentence_scores)\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def Xray_scorer(hadm_ID,best_sgd,noteevents_cleaned_dframe):\n",
    "    import numpy as np\n",
    "    hadm_ID_notes = noteevents_cleaned_dframe[noteevents_cleaned_dframe['HADM_ID'] == hadm_ID][['TEXT']]\n",
    "    hadm_ID_notes['Cleaned_text'] = hadm_ID_notes['TEXT'].apply(text_cleaner)\n",
    "    hadm_ID_notes['Sentences'] = hadm_ID_notes['Cleaned_text'].apply(sentence_tokenizer)\n",
    "    hadm_ID_notes['ARDS_Sentences'] = hadm_ID_notes['Sentences'].apply(lambda row: ARDS_sentence_scorer(row,best_sgd)[0])\n",
    "    hadm_ID_notes['ARDS_sentences_scores'] = hadm_ID_notes['Sentences'].apply(lambda row: ARDS_sentence_scorer(row,best_sgd)[1])\n",
    "    hadm_ID_notes['Step4_positive'] = np.where(hadm_ID_notes['ARDS_Sentences'].str.len()>0,1,0)\n",
    "    return {hadm_ID:hadm_ID_notes}\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def radiology_result(hadm_ID,best_sgd, noteevents_cleaned_dframe,print_results = True):\n",
    "    result_of_xray = 'Negative_radiology'\n",
    "    result_df = Xray_scorer(hadm_ID,best_sgd,noteevents_cleaned_dframe)[hadm_ID]\n",
    "    count_of_pos_sentences = result_df.Step4_positive.sum()\n",
    "    if count_of_pos_sentences>0:\n",
    "        result_of_xray = 'Positive_radiology'\n",
    "    if print_results:\n",
    "        print('# positive sentences: ', count_of_pos_sentences)\n",
    "        ARDS_sentences        = [item for List in result_df[result_df.ARDS_Sentences.str.len()>0]['ARDS_Sentences'].tolist() for item in List]\n",
    "        ARDS_sentences_scores = [item for List in result_df[result_df.ARDS_sentences_scores.str.len()>0]['ARDS_sentences_scores'].tolist() for item in List]\n",
    "        for i in range(len(ARDS_sentences)):\n",
    "            print('{} ---> score: {:.2f}'.format(ARDS_sentences[i],ARDS_sentences_scores[i]))\n",
    "    return {hadm_ID: result_of_xray}\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def sentence_grouper_for_chf(sentences):\n",
    "    '''\n",
    "    This function finds sentence groups for CHF scoring just like the pipleline we used for prepraing the test set. \n",
    "        \n",
    "    Note: The first sentence will be excluded because of the way I defined test set:  \n",
    "           - \"Most of the time, when it is the first sentence of the note, it just says the purpose of radiology. So, I will exclude it.\"\n",
    "    '''\n",
    "    import re\n",
    "#     import math  \n",
    "#     number_of_groups = math.floor((len(sentences)-1)/3)\n",
    "#     number_of_sentences_in_the_last_group = (len(sentences)-1)%3\n",
    "#     first_element    = [sentences[0]]\n",
    "#     last_element     = [' '.join(sentences[-number_of_sentences_in_the_last_group:])] if number_of_sentences_in_the_last_group > 0 else []\n",
    "#     middle_elements  = [' '.join(sentences[3*k+1:3*k+4]) for k in range(number_of_groups)]\n",
    "#     grouped_sentences= first_element+middle_elements+last_element\n",
    "#     return grouped_sentences\n",
    "\n",
    "    chf_regex_rules = [r'cardiac[\\s\\S]{0,3}shock', r'cardiac[\\s\\S]{0,3}arrest',r'cardiac[\\s\\S]{0,3}failure', r'heart[\\s\\S]{0,3}failure', r'\\bchf\\b', 'hydrostatic', 'hypervolemia', r'volume[\\s\\S]{0,3}overload', r'fluid[\\s\\S]{0,3}overload',r'systolic[\\s\\S]{0,3}dysfunction',r'diastolic[\\s\\S]{0,3}dysfunction','lvsd', 'lvdd', 'cardiogenic','lvsdysfunction','rvsdysfunction','lvddysfunction','rvddysfunction']\n",
    "\n",
    "    sentences_indicator_list = [any([(re.search(rule,sentence.lower()) is not None) for rule in chf_regex_rules]) for sentence in sentences]\n",
    "    chf_sentence_indices     = [index for index, truefalse in enumerate(sentences_indicator_list) if truefalse == True]\n",
    "    chf_grouped_sentences_list = []\n",
    "    for chf_sentence_index in chf_sentence_indices:\n",
    "        if chf_sentence_index==0:\n",
    "                chf_phrase_indices = [0]\n",
    "        elif chf_sentence_index==len(sentences_indicator_list)-1:\n",
    "            chf_phrase_indices = [chf_sentence_index-1,chf_sentence_index]\n",
    "        else:\n",
    "            chf_phrase_indices = [chf_sentence_index-1,chf_sentence_index,chf_sentence_index+1]\n",
    "        try:\n",
    "            chf_phrase = ' '.join([sentences[index] for index in chf_phrase_indices])\n",
    "            chf_grouped_sentences_list.append(chf_phrase)\n",
    "        except IndexError:  # To handle notes with only one sentence\n",
    "            pass\n",
    "    return chf_grouped_sentences_list\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def pre_scoring_text_prepration(text):\n",
    "    '''\n",
    "    This function prepares the text for chf scoring. This prep was done to improve the accuracy of the model.\n",
    "    '''\n",
    "    import re\n",
    "    cleaned_text =  re.sub('congestive heart failure','chf', text,         flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('heart failure','heartfailure',   cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(fluid overload|volume overload)','fluidoverload', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('cardiac arrest','cardiacarrest', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\br[/\\s]{0,1}o\\b|rule out)','ruleout', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\bh[/\\s]{0,1}o\\b|history of)','historyof', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bvs\\.', 'versus',                cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bvs\\b', 'versus',                cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('\\beval\\b','evaluate',               cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('left ventricular systolic dysfunction', 'lvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('right ventricular systolic dysfunction','rvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('lv systolic dysfunction','lvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('rv systolic dysfunction','rvsdysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('left ventricular diastolic dysfunction', 'lvddysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('right ventricular diastolic dysfunction','rvddysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('lv diastolic dysfunction','lvddysfunction', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('rv diastolic dysfunction','rvddysfunction', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub('left ventricular','leftventricular', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub('right ventricular','rightventricular', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blv\\b','leftventricular',  cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'\\brv\\b','rightventricular', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'acute[\\s\\S]{0,3}respiratory[\\s\\S]{0,3}distress[\\s\\S]{0,3}syndrome','ards', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'adult[\\s\\S]{0,3}respiratory[\\s\\S]{0,3}distress[\\s\\S]{0,3}syndrome','ards', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\brll\\b','rightlowerlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blll\\b','leftlowerlobe', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{0,3}lower[\\s\\S]{0,3}lobe','rightlowerlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{0,3}lower[\\s\\S]{0,3}lobe','leftlowerlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\brul\\b','rightupperlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blul\\b','leftupperlobe', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{0,3}upper[\\s\\S]{0,3}lobe','rightupperlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{0,3}upper[\\s\\S]{0,3}lobe', 'leftupperlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\brml\\b','rightmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\blml\\b','leftmiddlelobe', cleaned_text, flags=re.IGNORECASE) \n",
    "    cleaned_text =  re.sub(r'right[\\s\\S]{0,3}middle[\\s\\S]{0,3}lobe','rightmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left[\\s\\S]{0,3}middle[\\s\\S]{0,3}lobe', 'leftmiddlelobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'air[\\s\\S]{0,3}space[\\s\\S]{0,3}disease', 'airspacedisease', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right lung', 'rightlung', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left lung', 'leftlung', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'right lobe', 'rightlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'left lobe' , 'leftlobe', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'ground[\\s\\S]{0,3}glass', 'groundglass', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bpna\\b', 'pneumonia', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'(\\bs[\\s/]{0,1}p\\b|status post)', 'statuspost', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bpna\\b', 'pneumonia', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'\\bpls\\b', 'please', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'clip[\\s\\S]{0,6}clip', 'clip', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'clip[\\s\\S]{0,2}number', 'clipnumber', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'reason for this examination', 'reasonforthisexamination', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'chest[\\s\\S]{0,2}portable[\\s\\S]{0,2}ap', 'chestportableap', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'medical[\\s\\S]{0,2}condition', 'medicalcondition', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'pulmonary edema', 'pulmonarydema', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'consistent with', 'consistentwith', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'ill[\\s\\S]{0,1}defined', 'illdefined', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'final report', 'finalreport', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'no chf', 'nochf', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'admitting diagnos', 'admittingdiagnos', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'multi[\\s\\S]{1,2}focal', 'multifocal', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'', '', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'', '', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'', '', cleaned_text, flags=re.IGNORECASE)\n",
    "    cleaned_text =  re.sub(r'', '', cleaned_text, flags=re.IGNORECASE)\n",
    "    return  cleaned_text\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def sentence_finder_for_bilatOpac(sentences):\n",
    "    '''\n",
    "    This function takes the list of all sentences (output of tokenizer) and returns a list of the ones that include bilateral opacities keywords\n",
    "    '''\n",
    "    import re\n",
    "    \n",
    "    Rule1  = r'(opaci|infiltr|consolid|air[\\s\\S]{0,3}space[\\s\\S]{0,3}disease|pneumon|aspiration|\\bards\\b|respiratory[\\s\\S]{0,3}distress[\\s\\S]{0,3}syndrome)'\n",
    "    Rule2  = r'(bilateral|biapical|bibasilar|widespread|diffuse|perihilar|parahilar|multifocal|extensive|both|lungs|left|right)[\\s\\S]*(marking|infection|pattern|densit|abnormalit|haziness|hazy|process)'\n",
    "    Rule3  = r'(marking|infection|pattern|densit|abnormalit|haziness|hazy|process)[\\s\\S]*(bilateral|biapical|bibasilar|widespread|diffuse|perihilar|parahilar|multifocal|extensive|both|lungs|left|right)'\n",
    "    \n",
    "    bilatOpac_sentences_list = [sentence for sentence in sentences if (re.search(Rule1,sentence.lower()) is not None) or \n",
    "                                                                      (re.search(Rule2,sentence.lower()) is not None) or \n",
    "                                                                      (re.search(Rule3,sentence.lower()) is not None)]\n",
    "    return bilatOpac_sentences_list\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def profile_pdf_writer(hadm_id, filename,  directory ='/home/amir/Desktop/Project_ARDS/ARDS/', conn = connection):\n",
    "    \"\"\"\n",
    "    This function grabs patinet's profile from differet tables and prints them on a pdf:\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import pdfkit as pdf\n",
    "    import os\n",
    "\n",
    "    profile_query = '''\n",
    "    select A.HADM_ID,P.SUBJECT_ID, P.GENDER, datediff(A.ADMITTIME,DOB)/365 as AGE\n",
    "    ,A.Ethnicity, A.Marital_status, A.Religion, A.Language, A.Insurance, P.DOB,\n",
    "    A.ADMITTIME, A.ADMISSION_TYPE, A.Admission_location, P.DOD,\n",
    "    A.Discharge_location, A.Diagnosis,I.DBSource \n",
    "    from ADMISSIONS A join ICUSTAYS I on I.HADM_ID=A.HADM_ID \n",
    "    join PATIENTS P on A.SUBJECT_ID=P.SUBJECT_ID where A.HADM_ID = {}\n",
    "    '''.format(hadm_id)\n",
    "\n",
    "    profile_df = pd.read_sql_query(profile_query, conn)\n",
    "    \n",
    "    profile_df = profile_df.set_index(['HADM_ID','SUBJECT_ID','GENDER','AGE','Ethnicity','Marital_status','Religion',\n",
    "                              'Language','Insurance','DOB','ADMITTIME','ADMISSION_TYPE','Admission_location',\n",
    "                              'DOD','Discharge_location','Diagnosis','DBSource']).T\n",
    "    profile_df.to_html(directory + filename + '.html')\n",
    "    pdf.from_file(directory + filename + '.html', directory + filename)\n",
    "    os.remove(directory + filename + '.html')\n",
    "    print(\"Metadata for hadmID = {} written in a pdf file\".format(hadm_id))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def CHF_notes_finder(hadm_ID, terms, conn = connection):\n",
    "    '''\n",
    "    This function finds all notes (except for discharge summaries) that include at least of the keywords and returns them in order.\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    sql_condition = ''\n",
    "    for term in terms:\n",
    "        sql_condition += \"TEXT LIKE '%%{}%%' OR \".format(term)\n",
    "\n",
    "    sql_condition = '(' + sql_condition[:-3] + ')'\n",
    "    chf_notes_query = '''\n",
    "    SELECT CHARTDATE, CATEGORY, DESCRIPTION,TEXT FROM NOTEEVENTS \n",
    "    WHERE HADM_ID = {} AND \n",
    "    CATEGORY NOT LIKE 'Discharge summary' AND\n",
    "    {}\n",
    "    ORDER BY CHARTDATE\n",
    "    '''.format(hadm_ID,sql_condition)\n",
    "    CHF_notes_df = pd.read_sql_query(chf_notes_query, conn)\n",
    "    space = '&nbsp;'*50\n",
    "    text = ''\n",
    "    for index, row in CHF_notes_df.iterrows():\n",
    "        note = '''\n",
    "=================================================================\n",
    "=================================================================\n",
    "  HAMD_ID: {} {} Date: {} \n",
    "           \n",
    "  Cateroy: {} {} DESCRIPTION: {}\n",
    "=================================================================\n",
    "=================================================================\n",
    "        \n",
    "        {} <p class=\"new-page\"> </p>\n",
    "        '''.format(hadm_ID,space, row['CHARTDATE'], row['CATEGORY'],space, row['DESCRIPTION'],row['TEXT'])\n",
    "        text += note\n",
    "    return text\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def discharge_note_finder(hadm_ID,conn = connection):\n",
    "    import pandas as pd\n",
    "    discharge_query = '''\n",
    "    SELECT CHARTDATE, CATEGORY, DESCRIPTION,TEXT FROM NOTEEVENTS \n",
    "    WHERE HADM_ID = {} AND\n",
    "    CATEGORY LIKE 'Discharge summary'\n",
    "    ORDER BY CHARTDATE\n",
    "    '''.format(hadm_ID)\n",
    "    discharge_text_df = pd.read_sql_query(discharge_query, conn)\n",
    "    space = '&nbsp;'*50\n",
    "    text = ''\n",
    "    for index, row in discharge_text_df.iterrows():\n",
    "        note = '''\n",
    "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "  HAMD_ID: {} {} Date: {} \n",
    "           \n",
    "  Cateroy: {} {} DESCRIPTION: {}\n",
    "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
    "        \n",
    "        {} <p class=\"new-page\"> </p>\n",
    "        '''.format(hadm_ID,space, row['CHARTDATE'], row['CATEGORY'],space, row['DESCRIPTION'],row['TEXT'])\n",
    "        text += note\n",
    "    return text\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def highliter_pdf_printer(text, terms, filename = 'test', directory ='/home/amir/Desktop/Project_ARDS/ARDS/'):\n",
    "    '''\n",
    "    This function takes a text string and prints it on a pdf with the terms highlighted. \n",
    "    terms is a list.\n",
    "    '''\n",
    "    import pdfkit\n",
    "    import os\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    for term in terms:\n",
    "        re_object = re.compile(re.escape(term), re.IGNORECASE)\n",
    "        text = re_object.sub('<span style=\"background-color: #FFFF00;color:red;font-weight: bold\">' + term +'</span>',text)\n",
    "    \n",
    "    #This is to have \\n treated as line break:\n",
    "\n",
    "    text = '''\n",
    "    <style>\n",
    "    @media print {\n",
    "    .new-page {\n",
    "    page-break-before: always;\n",
    "        }\n",
    "    }\n",
    "    </style>\n",
    "    <span style=\"white-space: pre-line\">\n",
    "    '''+ text + '</span>'\n",
    "    \n",
    "    with open(directory + 'temp_html.html','w') as file:\n",
    "        file.write(text)\n",
    "    pdfkit.from_file(directory+'temp_html.html', directory+filename)\n",
    "    os.remove(directory+'temp_html.html')  \n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def chartlab_inverter(hadm_ID, Chart_item_dict, Chartevents_df, Lab_item_dict, Labevents_df):\n",
    "    # This functions transposes all relavant chart and lab items.\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    #ChartEVENTS______________________________________________________________________________________________________________________\n",
    "\n",
    "    text_items = [722,223848,720,223849,467,226732,468] #These are text items for which we should get VALUE not VALUENUM\n",
    "    chart_df = Chartevents_df[Chartevents_df.HADM_ID==hadm_ID].sort_values(by='CHARTTIME').copy()\n",
    "    transposed_chart_df = pd.DataFrame(columns=['HADM_ID_chart', 'SUBJECT_ID_chart']+sorted([item for item in list(set(Chart_item_dict.values()))]))\n",
    "    dtms   = chart_df.CHARTTIME.unique()\n",
    "    transposed_chart_df['CHARTTIME']        = dtms\n",
    "    transposed_chart_df['HADM_ID_chart']    = hadm_ID\n",
    "    \n",
    "    if len(chart_df)>0: \n",
    "        transposed_chart_df['SUBJECT_ID_chart'] = chart_df['SUBJECT_ID'].values[0] \n",
    "    else: \n",
    "        transposed_chart_df['SUBJECT_ID_chart'] = np.NaN\n",
    "    transposed_chart_df = transposed_chart_df.set_index(['CHARTTIME'])\n",
    "    \n",
    "    for index,row in chart_df.iterrows():\n",
    "        if row['ITEMID'] in text_items:\n",
    "            transposed_chart_df.loc[row['CHARTTIME'],Chart_item_dict[row['ITEMID']]] = row['VALUE']\n",
    "        else:\n",
    "            transposed_chart_df.loc[row['CHARTTIME'],Chart_item_dict[row['ITEMID']]] = row['VALUENUM']\n",
    "        \n",
    "    transposed_chart_df = transposed_chart_df.dropna(how = 'all').reset_index()\n",
    "#     display(transposed_chart_df)\n",
    "    transposed_chart_df['FiO2_chart'] = transposed_chart_df['FiO2_percent_chart'].fillna(transposed_chart_df['FiO2_decimal_chart']*100)\n",
    "    transposed_chart_df.drop(['FiO2_decimal_chart','FiO2_percent_chart'],axis = 1, inplace=True)\n",
    "    \n",
    "    #Labevents_____________________________________________________________________________________________________________________\n",
    "                                                                                                                   \n",
    "    lab_df = Labevents_df[Labevents_df.HADM_ID==hadm_ID].sort_values(by='CHARTTIME').copy()\n",
    "    transposed_lab_df = pd.DataFrame(columns=['HADM_ID_lab', 'SUBJECT_ID_lab'] + [item for item in list(set(Lab_item_dict.values()))])\n",
    "    dtms   = lab_df.CHARTTIME.unique() \n",
    "    transposed_lab_df['CHARTTIME']   = dtms\n",
    "    transposed_lab_df['HADM_ID_lab'] = hadm_ID\n",
    "    \n",
    "    if len(lab_df)>0: \n",
    "        transposed_lab_df['SUBJECT_ID_lab'] = lab_df['SUBJECT_ID'].values[0] \n",
    "    else: \n",
    "        transposed_lab_df['SUBJECT_ID_lab'] = np.NaN\n",
    "        \n",
    "        \n",
    "    transposed_lab_df = transposed_lab_df.set_index(['CHARTTIME'])\n",
    "    for index,row in lab_df.iterrows():\n",
    "        transposed_lab_df.loc[row['CHARTTIME'],Lab_item_dict[row['ITEMID']]] = row['VALUENUM']\n",
    "        \n",
    "    transposed_lab_df = transposed_lab_df.dropna(how = 'all').reset_index()\n",
    "    \n",
    "    \n",
    "    combined_transposed_df = pd.merge(transposed_chart_df,transposed_lab_df, how ='outer', on = 'CHARTTIME' )\n",
    "    combined_transposed_df.sort_values(by = 'CHARTTIME', inplace = True)\n",
    "    # Convert vent mode and type columns to string:  \n",
    "#     combined_transposed_df[['Vent_Type','Vent_Mode']] = combined_transposed_df[['Vent_Type','Vent_Mode']].fillna('')\n",
    "#     combined_transposed_df[['Vent_Type','Vent_Mode']] = combined_transposed_df[['Vent_Type','Vent_Mode']].astype(str)\n",
    "    \n",
    "    \n",
    "    # Giving priority to Lab data: \n",
    "    for measure in ['PaO2','FiO2', 'PaCO2', 'PH', 'SaO2', 'HADM_ID', 'SUBJECT_ID']:\n",
    "        combined_transposed_df[measure] = combined_transposed_df[measure +'_lab'].fillna(combined_transposed_df[measure +'_chart'])\n",
    "        combined_transposed_df.drop([measure +'_lab',measure +'_chart'],axis = 1, inplace=True)\n",
    "    \n",
    "\n",
    "    # When O2_device is None flow is zero:\n",
    "    combined_transposed_df.loc[combined_transposed_df['O2_Device']=='None','O2_Flow']   = 0\n",
    "    combined_transposed_df.loc[combined_transposed_df['O2_Device2']=='None','O2_Flow2'] = 0\n",
    "\n",
    "    combined_transposed_df = combined_transposed_df.reindex(['SUBJECT_ID','HADM_ID'] + sorted(combined_transposed_df.columns.drop(['HADM_ID','SUBJECT_ID'])), axis=1)\n",
    "#     if len(combined_transposed_df[pd.notnull(combined_transposed_df['O2_Device2'])])>0:\n",
    "#         display(combined_transposed_df)\n",
    "    return combined_transposed_df\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def T_intub_extub_finder(hadm_ID, Chart_item_dict, Chartevents_df, Lab_item_dict, Labevents_df,\n",
    "                   Intub_procedureEvents_MV_df, DBase_source_df, Paralytics_MV_df, Paralytics_CV_df, \n",
    "                   Extub_procedureEvents_MV_df):\n",
    "    '''\n",
    "    NO LONGER: Paralytics are considered only when patient has vent parameters, because I found cases where patints has paralytics administered but not intubated (e.g., hadm_ID = 176370). \n",
    "    We add a condition to include only drips and will let having no vent_record with paralytics. \n",
    "    Procedures are considered regardless of vent parameters. I found a cases where the patient is intubated but no vent is recorded (hadm_ID = 178929)\n",
    "    '''\n",
    "    import warnings\n",
    "    import datetime\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "    \n",
    "    ChartLab_inverted_df = chartlab_inverter(hadm_ID, Chart_item_dict, Chartevents_df, Lab_item_dict, Labevents_df)\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    # First vent_parameter dtm\n",
    "    vent_parameter_df = \\\n",
    "    ChartLab_inverted_df[(\\\n",
    "                 (pd.notnull(ChartLab_inverted_df.Mean_Airway_P))|\\\n",
    "                 (pd.notnull(ChartLab_inverted_df.Peak))|\\\n",
    "                 (pd.notnull(ChartLab_inverted_df.PEEP))|\\\n",
    "                 (pd.notnull(ChartLab_inverted_df.Plateau_P))|\\\n",
    "                 (pd.notnull(ChartLab_inverted_df.TV_Obsed))|\\\n",
    "                 (pd.notnull(ChartLab_inverted_df.TV_Set))|\\\n",
    "                 (pd.notnull(ChartLab_inverted_df.TV_Spont))\\\n",
    "                )\\\n",
    "                & (~ChartLab_inverted_df.Vent_Type.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\\\n",
    "                & (~ChartLab_inverted_df.Vent_Mode.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\\\n",
    "               ]\n",
    "    first_vent_parameter_dtm = vent_parameter_df.CHARTTIME.min()\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    #  O2_delivery method:\n",
    "    O2_delivery_method_df = \\\n",
    "    ChartLab_inverted_df[(ChartLab_inverted_df.O2_Device == 'Ventilator')|\n",
    "                         (ChartLab_inverted_df.O2_Device == 'Endotracheal tube')  \n",
    "#                          & (~ChartLab_inverted_df.Vent_Type.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\\\n",
    "#                          & (~ChartLab_inverted_df.Vent_Mode.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\\\n",
    "                        ]\n",
    "    first_O2_delivery_method_dtm = O2_delivery_method_df.CHARTTIME.min()\n",
    "    \n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    #  Intubation procdure in the PROCEDUREEVENTS_MV, Only applies to Metavision patients. (Item 224385\tIntubation\t4,514 patients)\n",
    "    procedure_df = Intub_procedureEvents_MV_df[Intub_procedureEvents_MV_df.HADM_ID==hadm_ID]\n",
    "#     if len(procedure_df)>1:\n",
    "#         print('hadm_ID={} has likely had reintubaion!'.format(hadm_ID))\n",
    "    procedure_dtm = procedure_df.ENDTIME.min()\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    #  Paralytic drugs. I would need to check if the patient is MV or CV.\n",
    "    \n",
    "    dbase = np.NaN\n",
    "    dbase_df = DBase_source_df[DBase_source_df.HADM_ID==hadm_ID]\n",
    "    if len(dbase_df)>0:\n",
    "        dbase = dbase_df.DBSOURCE.tolist()[0]        \n",
    "    # DBSOURCE is 'metavision', 'carevue', or 'both'. There are only 150 'both's. I will just query carevue for those cases. Risk is mitigated by other T_0 factors.\n",
    "\n",
    "    if dbase == 'metavision':\n",
    "#         print('MV----')\n",
    "        paralytics_df  = Paralytics_MV_df[Paralytics_MV_df.HADM_ID==hadm_ID]\n",
    "        paralytics_dtm = paralytics_df.STARTTIME.min()\n",
    "    else:\n",
    "#         print('CV----')\n",
    "        paralytics_df = Paralytics_CV_df[Paralytics_CV_df.HADM_ID==hadm_ID]\n",
    "        paralytics_dtm = paralytics_df.CHARTTIME.min()\n",
    "\n",
    "    T_intubs = [first_vent_parameter_dtm,first_O2_delivery_method_dtm, procedure_dtm, paralytics_dtm]\n",
    "    \n",
    "    try:\n",
    "        T_intub  = min([T for T in T_intubs if ((isinstance(T, datetime.datetime)) & (pd.notnull(T)))])\n",
    "    except ValueError:\n",
    "        T_intub = np.NaN\n",
    "        \n",
    "    # T_extub:\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    # Last vent_parameter dtm\n",
    "    extub_vent_parameter_df = ChartLab_inverted_df[(\n",
    "        (pd.notnull(ChartLab_inverted_df.Mean_Airway_P))|\n",
    "        (pd.notnull(ChartLab_inverted_df.Peak))|\n",
    "        (pd.notnull(ChartLab_inverted_df.PEEP))|\n",
    "        (pd.notnull(ChartLab_inverted_df.Plateau_P))|\n",
    "        (pd.notnull(ChartLab_inverted_df.TV_Obsed))|\n",
    "        (pd.notnull(ChartLab_inverted_df.TV_Set))|\n",
    "        (pd.notnull(ChartLab_inverted_df.TV_Spont))|\n",
    "        (ChartLab_inverted_df.O2_Device == 'Ventilator'))\n",
    "        & (~ChartLab_inverted_df.Vent_Type.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))\n",
    "        & (~ChartLab_inverted_df.Vent_Mode.astype(str).str.contains(r'(NIV|VAPS|BiPAP|CPAP)', regex=True,case=False))]\n",
    "    last_vent_parameter_dtm = extub_vent_parameter_df.CHARTTIME.max()\n",
    "#     print('last_vent_parameter_dtm',last_vent_parameter_dtm)\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    ##______________________________________________________________________________________________________________\n",
    "    \n",
    "    extub_procedure_df  = Extub_procedureEvents_MV_df[Extub_procedureEvents_MV_df.HADM_ID==hadm_ID]\n",
    "    extub_procedure_dtm = extub_procedure_df.ENDTIME.min()\n",
    "    \n",
    "    # First non-vent O2 delivery method after last vent parameter:\n",
    "    NoneVent_O2_method_after_intub_df = ChartLab_inverted_df[(ChartLab_inverted_df.CHARTTIME>last_vent_parameter_dtm)& \\\n",
    "                                                             (pd.notnull(ChartLab_inverted_df.O2_Device)) & \\\n",
    "                                                             (~ChartLab_inverted_df.Vent_Mode.astype(str).str.contains(r'(ventilator)', regex=True,case=False))]\n",
    "#     display(NoneVent_O2_method_after_intub_df)\n",
    "    first_NoneVent_method_after_intub_dtm = NoneVent_O2_method_after_intub_df.CHARTTIME.min()\n",
    "    \n",
    "    \n",
    "    T_extubs = [extub_procedure_dtm, first_NoneVent_method_after_intub_dtm]\n",
    "#     print(T_intubs)\n",
    "    try:\n",
    "        T_extub = min([T for T in T_extubs if ((isinstance(T, datetime.datetime)) & (pd.notnull(T)))])\n",
    "    except ValueError:\n",
    "        T_extub = np.NaN\n",
    "#     if any([pd.notnull(T) for T in T_extubs]):\n",
    "#         delta_Ts = [(T-T_extub).total_seconds()/3600 for T in T_extubs if pd.notnull(T)]\n",
    "#         print([round(delta_T,2) for delta_T in delta_Ts])\n",
    "#     print('---------------------------')\n",
    "\n",
    "    return T_intub,T_extub\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def admit_discharg_expire_dtm_finder(hadm_ID, Admissions_df):\n",
    "    '''\n",
    "    This functions finds [T_admit, T_discharge, T_expired, disposition_category] for each hadm_ID\n",
    "    '''\n",
    "    hadm_df    = Admissions_df[Admissions_df.HADM_ID==hadm_ID].copy()\n",
    "#     display(hadm_df)\n",
    "#     print(hadm_df.values.tolist()[0][:3])\n",
    "    discharge_mapping_dict = {\n",
    "        'HOME':                     'Home',\n",
    "        'HOME HEALTH CARE':         'Home',\n",
    "        'SNF':                      'Facility',\n",
    "        'REHAB/DISTINCT PART HOSP': 'Facility',\n",
    "        'DEAD/EXPIRED':             'Expired',\n",
    "        'LONG TERM CARE HOSPITAL':  'Facility',\n",
    "        'SHORT TERM HOSPITAL':      'Facility',#!!!!!!!!!!!!!?????????????\n",
    "        'DISC-TRAN CANCER/CHLDRN H':'Facility',\n",
    "        'DISCH-TRAN TO PSYCH HOSP': 'Facility',\n",
    "        'HOSPICE-HOME':             'Hospice',\n",
    "        'LEFT AGAINST MEDICAL ADVI':'Home',\n",
    "        'HOSPICE-MEDICAL FACILITY': 'Hospice',\n",
    "        'HOME WITH HOME IV PROVIDR':'Home',\n",
    "        'OTHER FACILITY':           'Facility',\n",
    "        'ICF':                      'Facility',\n",
    "        'DISC-TRAN TO FEDERAL HC':  'Facility',\n",
    "        'SNF-MEDICAID ONLY CERTIF': 'Facility'\n",
    "        }\n",
    "    disposition_category = discharge_mapping_dict[hadm_df.DISCHARGE_LOCATION.tolist()[0]]\n",
    "\n",
    "    return hadm_df.values.tolist()[0][1:4]+[disposition_category]  #[T_admit, T_discharge, T_expired, disposition_category]\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def add_event(ChartLab_inverted_df, event_name, event_dtm):\n",
    "    '''\n",
    "    Sometimes things overwrite each other. For example, admission may happen at the same time as intubation. To avoid this, \n",
    "    I will not add the event to the exisint dtm. I have done this with the following but later I changed it:\n",
    "    '''\n",
    "#     if event_dtm in ChartLab_inverted_df.CHARTTIME.tolist():\n",
    "#             ChartLab_inverted_df.loc[ChartLab_inverted_df.CHARTTIME == event_dtm,'Events'] = event_name\n",
    "#         else:\n",
    "#            .....\n",
    "    if pd.notnull(event_dtm):\n",
    "        ChartLab_inverted_df = ChartLab_inverted_df.append({'CHARTTIME':event_dtm,'Events': event_name}, ignore_index = True)\n",
    "        return ChartLab_inverted_df\n",
    "    else:\n",
    "        return ChartLab_inverted_df\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def chest_radio_dtm_label_finder(hadm_ID, CXR_df, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier,\n",
    "                                 print_results = False):\n",
    "    import re\n",
    "    '''\n",
    "    This function takes the HADM_ID and returns two outputs:\n",
    "        1. List of tuples for bilat opacities: [(radiology1_dtm,pos_bilatOpac/neg_bilatOpac),(radiology2_dtm,pos_bilatOpac/neg_bilatOpac),... ]\n",
    "    where pos/neg is the label for the Berlin's chest imaging condition (i.e., \"Bilateral opacities not fully explained by effusions, lobar or lung collapse, or nodules\")? \n",
    "         2. List of tuples for CHF. \n",
    "    \n",
    "    In the new version of the function:\n",
    "        1. For bilatOpac, wqe only score sentences that include keywords for bilatOpac\n",
    "        2. For CHF, We will inlcude 'Echo' and 'Chest Xrays', with different classifiers built for each\n",
    "    '''\n",
    "    radios_df = CXR_df[CXR_df.HADM_ID==hadm_ID].copy()\n",
    "    \n",
    "    #Handling missing CHARTIMES (mostly for ECG and ECHO):\n",
    "    radios_df['CHARTTIME'] = radios_df.apply(lambda row: row['CHARTTIME'] if pd.notnull(row['CHARTTIME']) else pd.Timestamp(row['CHARTDATE']), axis=1)   \n",
    "    radios_df['Cleaned_text']        = radios_df['TEXT'].apply(text_cleaner)\n",
    "    radios_df['Sentences']           = radios_df['Cleaned_text'].apply(sentence_tokenizer)\n",
    "    \n",
    "    \n",
    "    #_____________________________________________________________________________________________________________________________________\n",
    "    # Bilat_Opac:\n",
    "    \n",
    "    # bilatOpac_sentences are all sentences that have bilatOpac keywords. \n",
    "    radios_df['bilatOpac_sentences']  = radios_df['Sentences'].apply(sentence_finder_for_bilatOpac)\n",
    "#     display(radios_df)\n",
    "    # ALSO, WE EXCLUDE NON-RADIOLOGY reports for BilaOpac:\n",
    "    len_before_elimination = len(radios_df[radios_df['bilatOpac_sentences'].str.len()>0])\n",
    "    radios_df.loc[radios_df.CATEGORY != 'Radiology', 'bilatOpac_sentences']  = np.NaN\n",
    "    radios_df.loc[pd.isnull(radios_df['bilatOpac_sentences']),'bilatOpac_sentences'] = radios_df['bilatOpac_sentences'].apply(lambda x: [])\n",
    "    len_after_elimination = len(radios_df[radios_df['bilatOpac_sentences'].str.len()>0])\n",
    "    radios_df['pos_bilatOpac_sentences'] = radios_df['bilatOpac_sentences'].apply(lambda row: ML_sentence_scorer(row,bilatOpac_classifier)[0])\n",
    "    \n",
    "   # _____________________________________________________________________________________________________________________________________\n",
    "    # CHF:\n",
    "   \n",
    "    # Group[] sentences that have CHF keywords:    \n",
    "    radios_df['Prepred_CHF_grouped_sentences']         = radios_df['Sentences'].apply(sentence_grouper_for_chf)\n",
    "#     radios_df['Prepred_CHF_grouped_sentences'] = radios_df.apply(lambda row: [pre_scoring_text_prepration(text) for text in row['CHF_grouped_sentences']],axis = 1)    \n",
    "    radios_df.loc[radios_df.CATEGORY=='Radiology','pos_CHF_sentences'] = radios_df['Prepred_CHF_grouped_sentences'].apply(lambda row: ML_sentence_scorer(row,radio_chf_classifier)[0])\n",
    "    radios_df.loc[radios_df.CATEGORY=='Echo',     'pos_CHF_sentences'] = radios_df['Prepred_CHF_grouped_sentences'].apply(lambda row: ML_sentence_scorer(row,echo_chf_classifier)[0])\n",
    "    \n",
    "    radios_df['bilatOpac_result']    = np.where(radios_df['pos_bilatOpac_sentences'].str.len()>0,'pos_bilatOpac','neg_bilatOpac')\n",
    "    radios_df['CHF_result']          = np.where(radios_df['pos_CHF_sentences'].str.len()>0,'pos_chf','neg_chf')\n",
    "    \n",
    "    if print_results:\n",
    "        \n",
    "#         display(radios_df)\n",
    "        \n",
    "#     # print whole report\n",
    "#         for text in radios_df['TEXT'].tolist():\n",
    "#             print(text)\n",
    "#             print('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ')\n",
    "    \n",
    "        \n",
    "        if len_after_elimination!=len_before_elimination:\n",
    "            print('Sentence(s) with bilateral opacity keywords was excluded from bilatOpac detector because they come from a non-Radiology for hadm_ID = {}'.format(hadm_ID))\n",
    "        \n",
    "        print('+++++++++++++++++++++++++++\\nPositive chfs:\\n+++++++++++++++++++++++++++')\n",
    "        for sent_list in radios_df[radios_df.CHF_result=='pos_chf']['pos_CHF_sentences'].tolist():\n",
    "            for sent in sent_list:\n",
    "                print(sent)\n",
    "                print('\\n')\n",
    "        \n",
    "        print('+++++++++++++++++++++++++++\\nPositive Bilateral Opacities:\\n+++++++++++++++++++++++++++')\n",
    "        for sent_list in radios_df[radios_df.bilatOpac_result=='pos_bilatOpac']['pos_bilatOpac_sentences'].tolist():\n",
    "            for sent in sent_list:\n",
    "                print(sent)\n",
    "                print('\\n')\n",
    "        \n",
    "        print('------------------------------\\nNegative chfs:\\n------------------------------')\n",
    "        for sent_list in radios_df[radios_df.CHF_result=='neg_chf']['Prepred_CHF_grouped_sentences'].tolist():  \n",
    "            for sent in sent_list:\n",
    "                chf_regex_rules = [r'cardiac[\\s\\S]{0,3}shock', r'cardiac[\\s\\S]{0,3}arrest',r'cardiac[\\s\\S]{0,3}failure', r'heart[\\s\\S]{0,3}failure', r'\\bchf\\b', 'hydrostatic', 'hypervolemia', r'volume[\\s\\S]{0,3}overload', r'fluid[\\s\\S]{0,3}overload',r'systolic[\\s\\S]{0,3}dysfunction',r'diastolic[\\s\\S]{0,3}dysfunction','lvsd', 'lvdd', 'cardiogenic','lvsdysfunction','rvsdysfunction','lvddysfunction','rvddysfunction']\n",
    "                if [any([(re.search(rule,sent.lower()) is not None) for rule in chf_regex_rules])]:\n",
    "                    print(sent)\n",
    "                    print('\\n')\n",
    "        \n",
    "        print('------------------------------\\nNegative Bilateral Opacities:\\n------------------------------')\n",
    "        Rule1  = r'(opaci|infiltr|consolid|air[\\s\\S]{0,3}space[\\s\\S]{0,3}disease|pneumon|aspiration|\\bards\\b|respiratory[\\s\\S]{0,3}distress[\\s\\S]{0,3}syndrome)'\n",
    "        Rule2  = r'(bilateral|biapical|bibasilar|widespread|diffuse|perihilar|parahilar|multifocal|extensive|both|lungs|left|right)[\\s\\S]*(marking|infection|pattern|densit|abnormalit|haziness|hazy|process)'\n",
    "        Rule3  = r'(marking|infection|pattern|densit|abnormalit|haziness|hazy|process)[\\s\\S]*(bilateral|biapical|bibasilar|widespread|diffuse|perihilar|parahilar|multifocal|extensive|both|lungs|left|right)'\n",
    "        for sent_list in radios_df[radios_df.bilatOpac_result=='neg_bilatOpac']['Sentences'].tolist():\n",
    "            for sent in sent_list:\n",
    "                candidate_sentence = [re.search(rule,sent.lower()) is not None for rule in [Rule1,Rule2,Rule3]]\n",
    "                if any(candidate_sentence):\n",
    "                    print(sent)\n",
    "                    print('\\n')\n",
    "        \n",
    "    return radios_df[['CHARTTIME','bilatOpac_result']].values.tolist() , radios_df[['CHARTTIME','CHF_result']].values.tolist()\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def chest_radio_dtm_label_saver_for_pdf(hadm_ID, CXR_df, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier,\n",
    "                                        store_text_results = False):\n",
    "    import re\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "#     print(hadm_ID)\n",
    "\n",
    "    radios_df = CXR_df[CXR_df.HADM_ID==hadm_ID].copy()\n",
    "    \n",
    "    #Handling missing CHARTIMES (mostly for ECG and ECHO):\n",
    "    radios_df['CHARTTIME'] = radios_df.apply(lambda row: row['CHARTTIME'] if pd.notnull(row['CHARTTIME']) else pd.Timestamp(row['CHARTDATE']), axis=1)   \n",
    "    radios_df['Cleaned_text']        = radios_df['TEXT'].apply(text_cleaner)\n",
    "    radios_df['Sentences']           = radios_df['Cleaned_text'].apply(sentence_tokenizer)\n",
    "    \n",
    "    \n",
    "    #_____________________________________________________________________________________________________________________________________\n",
    "    # Bilat_Opac:\n",
    "    \n",
    "    # bilatOpac_sentences are all sentences that have bilatOpac keywords. \n",
    "    radios_df['bilatOpac_sentences']  = radios_df['Sentences'].apply(sentence_finder_for_bilatOpac)\n",
    "#     display(radios_df)\n",
    "    # ALSO, WE EXCLUDE NON-RADIOLOGY reports for BilaOpac:\n",
    "    len_before_elimination = len(radios_df[radios_df['bilatOpac_sentences'].str.len()>0])\n",
    "    radios_df.loc[radios_df.CATEGORY != 'Radiology', 'bilatOpac_sentences']  = np.NaN\n",
    "    radios_df.loc[pd.isnull(radios_df['bilatOpac_sentences']),'bilatOpac_sentences'] = radios_df['bilatOpac_sentences'].apply(lambda x: [])\n",
    "    len_after_elimination = len(radios_df[radios_df['bilatOpac_sentences'].str.len()>0])\n",
    "    radios_df['pos_bilatOpac_sentences'] = radios_df['bilatOpac_sentences'].apply(lambda row: ML_sentence_scorer(row,bilatOpac_classifier)[0])\n",
    "   # _____________________________________________________________________________________________________________________________________\n",
    "    # CHF:\n",
    "   \n",
    "    # Group[] sentences that have CHF keywords:    \n",
    "    radios_df['Prepred_CHF_grouped_sentences']         = radios_df['Sentences'].apply(sentence_grouper_for_chf)\n",
    "    radios_df.loc[radios_df.CATEGORY=='Radiology','pos_CHF_sentences'] = radios_df['Prepred_CHF_grouped_sentences'].apply(lambda row: ML_sentence_scorer(row,radio_chf_classifier)[0])\n",
    "    radios_df.loc[radios_df.CATEGORY=='Echo',     'pos_CHF_sentences'] = radios_df['Prepred_CHF_grouped_sentences'].apply(lambda row: ML_sentence_scorer(row,echo_chf_classifier)[0])\n",
    "    \n",
    "    radios_df['bilatOpac_result']    = np.where(radios_df['pos_bilatOpac_sentences'].str.len()>0,'pos_bilatOpac','neg_bilatOpac')\n",
    "    radios_df['CHF_result']          = np.where(radios_df['pos_CHF_sentences'].str.len()>0,'pos_chf','neg_chf')\n",
    "    \n",
    "    if store_text_results:\n",
    "        \n",
    "#         display(radios_df)\n",
    "        \n",
    "#     # print whole report\n",
    "#         for text in radios_df['TEXT'].tolist():\n",
    "#             print(text)\n",
    "#             print('_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ')\n",
    "    \n",
    "        \n",
    "        if len_after_elimination!=len_before_elimination:\n",
    "            print('Sentence(s) with bilateral opacity keywords was excluded from bilatOpac detector because they come from a non-Radiology for hadm_ID = {}'.format(hadm_ID))\n",
    "        \n",
    "        text = ''\n",
    "        text1 = '\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\nPhrases classifed as positive for CHF:\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n'\n",
    "        text += text1\n",
    "        for sent_list in radios_df[radios_df.CHF_result=='pos_chf']['pos_CHF_sentences'].tolist():\n",
    "            for sent in sent_list:\n",
    "                text += '- ' + sent\n",
    "                text += '\\n'\n",
    "\n",
    "        text3 = '\\n-----------------------------------------------------------------\\nPhrases classifed as negative for CHF:\\n-----------------------------------------------------------------\\n'\n",
    "        text += text3\n",
    "        for sent_list in radios_df[radios_df.CHF_result=='neg_chf']['Prepred_CHF_grouped_sentences'].tolist():  \n",
    "            for sent in sent_list:\n",
    "                chf_regex_rules = [r'cardiac[\\s\\S]{0,3}shock', r'cardiac[\\s\\S]{0,3}arrest',r'cardiac[\\s\\S]{0,3}failure', r'heart[\\s\\S]{0,3}failure', r'\\bchf\\b', 'hydrostatic', 'hypervolemia', r'volume[\\s\\S]{0,3}overload', r'fluid[\\s\\S]{0,3}overload',r'systolic[\\s\\S]{0,3}dysfunction',r'diastolic[\\s\\S]{0,3}dysfunction','lvsd', 'lvdd', 'cardiogenic','lvsdysfunction','rvsdysfunction','lvddysfunction','rvddysfunction']\n",
    "                if [any([(re.search(rule,sent.lower()) is not None) for rule in chf_regex_rules])]:\n",
    "                    text += '- ' + sent\n",
    "                    text += '\\n'\n",
    "    \n",
    "        text2 = '\\n\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\nSentences classifed as positive for bilateral opacities:\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n'\n",
    "        text += text2\n",
    "        for sent_list in radios_df[radios_df.bilatOpac_result=='pos_bilatOpac']['pos_bilatOpac_sentences'].tolist():\n",
    "            for sent in sent_list:\n",
    "                text += '- ' + sent\n",
    "                text += '\\n'\n",
    "                \n",
    "        \n",
    "        text4 = '\\n-----------------------------------------------------------------\\nSentences classifed as negative for bilateral opacities:\\n-----------------------------------------------------------------\\n'\n",
    "        text += text4\n",
    "        Rule1  = r'(opaci|infiltr|consolid|air[\\s\\S]{0,3}space[\\s\\S]{0,3}disease|pneumon|aspiration|\\bards\\b|respiratory[\\s\\S]{0,3}distress[\\s\\S]{0,3}syndrome)'\n",
    "        Rule2  = r'(bilateral|biapical|bibasilar|widespread|diffuse|perihilar|parahilar|multifocal|extensive|both|lungs|left|right)[\\s\\S]*(marking|infection|pattern|densit|abnormalit|haziness|hazy|process)'\n",
    "        Rule3  = r'(marking|infection|pattern|densit|abnormalit|haziness|hazy|process)[\\s\\S]*(bilateral|biapical|bibasilar|widespread|diffuse|perihilar|parahilar|multifocal|extensive|both|lungs|left|right)'\n",
    "        for sent_list in radios_df[radios_df.bilatOpac_result=='neg_bilatOpac']['Sentences'].tolist():\n",
    "            for sent in sent_list:\n",
    "                candidate_sentence = [re.search(rule,sent.lower()) is not None for rule in [Rule1,Rule2,Rule3]]\n",
    "                if any(candidate_sentence):\n",
    "                    text += '- ' + sent\n",
    "                    text += '\\n'\n",
    "        \n",
    "    return radios_df[['CHARTTIME','bilatOpac_result']].values.tolist() , radios_df[['CHARTTIME','CHF_result']].values.tolist(),text\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def fill_forward_interventions (ChartLab_inverted_df, T_Intub, T_Extub,\n",
    "                                off_vent_interventions = ['O2_Device', 'O2_Flow','O2_Device2', 'O2_Flow2'],\n",
    "                                on_vent_interventions  = ['O2_Device', 'FiO2', 'PEEP', 'RR_Set','TV_Set','Vent_Mode','Vent_Type']):    \n",
    "    \n",
    "    # If intubated:\n",
    "    if pd.notnull(T_Intub):\n",
    "        # ffil off_vent_interventions before intubation:\n",
    "#         display(ChartLab_inverted_df)\n",
    "        ChartLab_inverted_df.loc[ChartLab_inverted_df.CHARTTIME<T_Intub,off_vent_interventions] =\\\n",
    "        ChartLab_inverted_df.loc[ChartLab_inverted_df.CHARTTIME<T_Intub,off_vent_interventions].ffill()\n",
    "        \n",
    "        # If extubated:\n",
    "        if pd.notnull(T_Extub):\n",
    "            # ffil on_vent_interventions between intubation and extubation:\n",
    "            ChartLab_inverted_df.loc[(ChartLab_inverted_df.CHARTTIME>=T_Intub)&(ChartLab_inverted_df.CHARTTIME<T_Extub),on_vent_interventions] =\\\n",
    "            ChartLab_inverted_df.loc[(ChartLab_inverted_df.CHARTTIME>=T_Intub)&(ChartLab_inverted_df.CHARTTIME<T_Extub),on_vent_interventions].ffill()\n",
    "            # ffil off_vent_interventions after extubation:\n",
    "            ChartLab_inverted_df.loc[ChartLab_inverted_df.CHARTTIME>=T_Extub,off_vent_interventions] =\\\n",
    "            ChartLab_inverted_df.loc[ChartLab_inverted_df.CHARTTIME>=T_Extub,off_vent_interventions].ffill()\n",
    "        # If never extubated:\n",
    "        else:\n",
    "            # ffil on_vent_interventions after intubation:\n",
    "            ChartLab_inverted_df.loc[(ChartLab_inverted_df.CHARTTIME>=T_Intub),on_vent_interventions] =\\\n",
    "            ChartLab_inverted_df.loc[(ChartLab_inverted_df.CHARTTIME>=T_Intub),on_vent_interventions].ffill()\n",
    "    \n",
    "    # If not intubated in hostpital:\n",
    "    else:\n",
    "        # If an extubation seen:\n",
    "        if pd.notnull(T_Extub):\n",
    "        # ffil on_vent_interventions before extubation:\n",
    "            ChartLab_inverted_df.loc[(ChartLab_inverted_df.CHARTTIME<T_Extub),on_vent_interventions] =\\\n",
    "            ChartLab_inverted_df.loc[(ChartLab_inverted_df.CHARTTIME<T_Extub),on_vent_interventions].ffill()\n",
    "        \n",
    "        # If not extubated either:\n",
    "        else:\n",
    "            # ffil off_vent_interventions all the way\n",
    "            ChartLab_inverted_df.loc[:,off_vent_interventions] = ChartLab_inverted_df.loc[:,off_vent_interventions].ffill()\n",
    "    return ChartLab_inverted_df\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def time_series_finder(hadm_ID, Chart_item_dict, Chartevents_df, Lab_item_dict, Labevents_df,\n",
    "                       Intub_procedureEvents_MV_df, DBase_source_df, Paralytics_MV_df, Paralytics_CV_df, \n",
    "                       Extub_procedureEvents_MV_df,\n",
    "                       Admissions_df,CXR_df, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier, \n",
    "                       max_possible_PtoF = 700, max_possible_PEEP = 25):\n",
    "    '''\n",
    "    Note: Only 64 (out of 5,853) expired hadms have different discharge and expired dtms. \n",
    "    '''\n",
    "    import warnings\n",
    "    import datetime\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "    \n",
    "    chartlab_df       = chartlab_inverter(hadm_ID, Chart_item_dict, Chartevents_df, Lab_item_dict, Labevents_df)\n",
    "    T_intub,T_extub   = T_intub_extub_finder(hadm_ID, Chart_item_dict, Chartevents_df, Lab_item_dict, Labevents_df,\n",
    "                                             Intub_procedureEvents_MV_df, DBase_source_df, Paralytics_MV_df, Paralytics_CV_df, \n",
    "                                             Extub_procedureEvents_MV_df)\n",
    "    \n",
    "    T_admit, T_discharge, T_death, disposition = admit_discharg_expire_dtm_finder(hadm_ID, Admissions_df)\n",
    "#     print('T_intub ', T_intub)\n",
    "#     print('T_extub ',T_extub)\n",
    "    \n",
    "    # Adding events:\n",
    "    chartlab_df = add_event(chartlab_df, 'Intubated', T_intub)\n",
    "    chartlab_df = add_event(chartlab_df, 'Extubated', T_extub)\n",
    "    chartlab_df = add_event(chartlab_df, 'Admitted', T_admit)\n",
    "    chartlab_df = add_event(chartlab_df, 'Discharged', T_discharge)\n",
    "    chartlab_df = add_event(chartlab_df, 'Disposition: '+disposition, T_discharge)\n",
    "    chartlab_df = add_event(chartlab_df, 'Expired', T_death)\n",
    "    bilatOpac_labels_list, chf_labels_list= chest_radio_dtm_label_finder(hadm_ID, CXR_df, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier)\n",
    "    if len(bilatOpac_labels_list)!=len(chf_labels_list):\n",
    "        print('bilatOpac_labels has different size than  chf_labels_list! investigate!')\n",
    "    for radio_index in range(len(bilatOpac_labels_list)):\n",
    "        chartlab_df = add_event(chartlab_df, bilatOpac_labels_list[radio_index][1], bilatOpac_labels_list[radio_index][0])\n",
    "        chartlab_df = add_event(chartlab_df, chf_labels_list[radio_index][1], chf_labels_list[radio_index][0])\n",
    "#     display(chartlab_df[chartlab_df.CHARTTIME.isnull()])\n",
    "    chartlab_df.sort_values(by = ['CHARTTIME','Events'], inplace = True)\n",
    "    \n",
    "    chartlab_df = fill_forward_interventions (chartlab_df, T_intub, T_extub)\n",
    "#     display(chartlab_df)\n",
    "    chartlab_df['Days_since_T_admit'] = (chartlab_df['CHARTTIME'] - T_admit).dt.total_seconds()/3600/24\n",
    "    chartlab_df['PtoF'] = 100*chartlab_df['PaO2']/chartlab_df['FiO2']\n",
    "#     \n",
    "    \n",
    "    # Cleaning:\n",
    "    chartlab_df.loc[chartlab_df['PEEP'] > max_possible_PEEP, 'PEEP'] = np.NaN\n",
    "    chartlab_df.loc[chartlab_df['PtoF'] > max_possible_PtoF, 'PtoF'] = np.NaN \n",
    "    \n",
    "    chartlab_df['HADM_ID']    = int(hadm_ID)\n",
    "    chartlab_df['SUBJECT_ID'] = int(chartlab_df['SUBJECT_ID'].dropna().tolist()[0])\n",
    "    return chartlab_df\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def imscatter(x, y, image, ax=None, zoom=1):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    try:\n",
    "        image = plt.imread(image)\n",
    "    except TypeError:\n",
    "        # Likely already an array...\n",
    "        pass\n",
    "    im = OffsetImage(image, zoom=zoom)\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    for x0, y0 in zip(x, y):\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def PtoF_PEEP_Events_plotter(hadm_ID,Time_series_dict,trach_O2_dtm_dict, trach_proc_dtm_dict,\n",
    "                             t_ticks_step = 1, events_font_size = 20, PtoF_ticks_step = 50, \n",
    "                             PEEP_ticks_step = 5,  max_possible_PtoF = 700, max_possible_PEEP = 25, \n",
    "                             figsize=(20, 10), legend=True, save_fig = False):  \n",
    "    \n",
    "    import matplotlib.pyplot as plt \n",
    "    import math\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "    \n",
    "    time_series_df = Time_series_dict[hadm_ID].copy()\n",
    "    first_dtm = time_series_df['Days_since_T_admit'].min()\n",
    "    last_dtm  = time_series_df['Days_since_T_admit'].max()\n",
    "    trach_dtms             = [dtm for dtm in [trach_proc_dtm_dict[hadm_ID],trach_O2_dtm_dict[hadm_ID]] if pd.notnull(dtm)]\n",
    "    first_trach_record_dtm = min(trach_dtms) if len(trach_dtms)>0 else np.NaN\n",
    "    first_trach_record_day = (first_trach_record_dtm-time_series_df.CHARTTIME.min()).total_seconds()/60/60/24 if pd.notnull(first_trach_record_dtm) else np.NaN\n",
    "    \n",
    "    plt.clf()    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    plt.rcParams['xtick.labelsize']=16\n",
    "    plt.rcParams['ytick.labelsize']=16\n",
    "    \n",
    "    #_____________________________________________________________________________________________________________________________________________________\n",
    "    # P/F:\n",
    "    ax.axhspan(0, 100, color='r', alpha=0.15)\n",
    "    ax.axhspan(100, 200, color='r', alpha=0.07)\n",
    "    ax.axhspan(200, 300, color='r', alpha=0.02)\n",
    "    PtoF_df = time_series_df[pd.notnull(time_series_df.PtoF)]\n",
    "    PtoF_df.plot(x = 'Days_since_T_admit' , y = 'PtoF', linestyle = 'solid', marker = 'o', color = '0.15',label = 'P/F', markersize= 6, linewidth = 2, ax = ax)    #_____________________________________________________________________________________________________________________________________________________ \n",
    "    # PEEP:\n",
    "    ax2 = ax.twinx()\n",
    "    PEEP_df = time_series_df[pd.notnull(time_series_df.PEEP)]\n",
    "    if len(PEEP_df)>0:\n",
    "        PEEP_df.plot(x = 'Days_since_T_admit' , y = 'PEEP', linestyle = 'solid', color = 'blue', linewidth = 1.5, ax = ax2, label = 'PEEP')  #_____________________________________________________________________________________________________________________________________________________\n",
    "    # Intubation/Extubation\n",
    "    times_markersize = 15\n",
    "\n",
    "    t_intub = time_series_df[time_series_df['Events']=='Intubated']['Days_since_T_admit'].values\n",
    "    t_extub = time_series_df[time_series_df['Events']=='Extubated']['Days_since_T_admit'].values\n",
    "\n",
    "    if (len(t_intub) > 0) & (len(t_extub) > 0):\n",
    "        ax.axvspan(t_intub, t_extub, color='black', alpha=0.05)\n",
    "        ax.axvline(x=t_intub, label = '', color = 'darkgreen',linewidth=2.0, linestyle = 'dashed')\n",
    "        ax.axvline(x=t_extub, label = '', color = 'darkgreen',linewidth=2.0, linestyle = 'dashed') \n",
    "        ax.plot(t_intub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "        ax.annotate('$T_{intubation}$',xy=(t_intub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "        ax.plot(t_extub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "        ax.annotate('$T_{extubation}$',xy=(t_extub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "\n",
    "    elif (len(t_intub) > 0) & (len(t_extub) == 0):\n",
    "        ax.axvspan(t_intub, last_dtm, color='black', alpha=0.05)\n",
    "        ax.axvline(x=t_intub, label = '', color = 'black',linewidth=2.0, linestyle = 'dotted')\n",
    "        ax.plot(t_intub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "        ax.annotate('$T_{intubation}$',xy=(t_intub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "        print('HADM_ID: {} was not extubated'.format(time_series_df[pd.notnull(time_series_df['HADM_ID'])]['HADM_ID'].tolist()[0]))        \n",
    "\n",
    "    elif (len(t_intub) == 0) & (len(t_extub) > 0):\n",
    "        ax.axvspan(0, t_extub, color='black', alpha=0.05)\n",
    "        ax.axvline(x=t_extub, label = '', color = 'black',linewidth=2.0, linestyle = 'dotted')\n",
    "        ax.plot(t_extub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "        ax.annotate('$T_{extubation}$',xy=(t_extub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "        print('HADM_ID: {} was intubated before arrival'.format(time_series_df[pd.notnull(time_series_df['HADM_ID'])]['HADM_ID'].tolist()[0]))\n",
    "    \n",
    "#     ____________________________________________________________________________________________________________________________________________________\n",
    "    # Tracheostomy:\n",
    "    if pd.notnull(first_trach_record_day):\n",
    "        ax.plot(first_trach_record_day,0,'o',color = 'purple',clip_on = False, markersize= times_markersize)\n",
    "        ax.annotate('$T^{0}_{trach}$',xy=(first_trach_record_day, 20),horizontalalignment='center', verticalalignment='bottom',\n",
    "                    fontsize = events_font_size+5 , annotation_clip=False, color = 'purple')\n",
    "    \n",
    "    #_____________________________________________________________________________________________________________________________________________________\n",
    "    # Discharge:\n",
    "    t_discharge = time_series_df[time_series_df['Events'].str.contains('Disposition',na=False)]['Days_since_T_admit'].values\n",
    "    disposition = time_series_df[time_series_df['Events'].str.contains('Disposition',na=False)]['Events'].values\n",
    "    ax.plot(t_discharge,0,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "    ax.annotate('$T_{discharge}$'+'({})'.format(disposition[0].split(': ')[1]),xy=(t_discharge, -60),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "    \n",
    "    #_____________________________________________________________________________________________________________________________________________________\n",
    "    # Positive/negative bilateral infiltrate in xrays:\n",
    "    t_pos_bilatOpac = time_series_df[time_series_df['Events']=='pos_bilatOpac']['Days_since_T_admit'].values\n",
    "    t_neg_bilatOpac = time_series_df[time_series_df['Events']=='neg_bilatOpac']['Days_since_T_admit'].values\n",
    "\n",
    "    label = True\n",
    "    for t in t_pos_bilatOpac:\n",
    "        ax.plot(t,max_possible_PtoF-10, clip_on = False, color = 'r', linestyle='', \n",
    "                label = 'Bilateral Opacities' if label else \"\")\n",
    "        imscatter(t, max_possible_PtoF-32, 'Icon_BilatOpac.png', zoom=0.028, ax=ax)\n",
    "        label = False\n",
    "    label = True\n",
    "\n",
    "\n",
    "    # CHF in xrays:\n",
    "    t_pos_chf = time_series_df[time_series_df['Events']=='pos_chf']['Days_since_T_admit'].values\n",
    "    t_neg_chf = time_series_df[time_series_df['Events']=='neg_chf']['Days_since_T_admit'].values\n",
    "\n",
    "    label = True\n",
    "    for t in t_pos_chf:\n",
    "        ax.plot(t,max_possible_PtoF+10, clip_on = False, color = 'r', linestyle='', label = 'Heart Failure/Fluid Overload' if label else \"\")\n",
    "        chf_y_delta = -70 if t in t_pos_bilatOpac else -32\n",
    "        imscatter(t, max_possible_PtoF+chf_y_delta, 'Icon_CHF.png', zoom=0.05, ax=ax)\n",
    "        label = False\n",
    "\n",
    "    # Radio/Echo Reports with no evidence of either bilat opac and infilterates\n",
    "    label = True\n",
    "    for t in set(t_neg_bilatOpac.tolist()+t_neg_chf.tolist()+t_pos_bilatOpac.tolist()+t_pos_chf.tolist()):\n",
    "        ax.plot(t,max_possible_PtoF, clip_on = False, color = 'black', marker= '$☐$', markersize= 15, linestyle='', label = 'Radio/Echo Report' if label else \"\")\n",
    "        label = False \n",
    "        \n",
    "    #_____________________________________________________________________________________________________________________________________________________\n",
    "    # Chart parameters:\n",
    "   \n",
    "    ax.tick_params(axis=\"x\", bottom=True, top=True, labelbottom=True, labeltop=False)   \n",
    "    ax.set_xlim(math.floor(first_dtm), last_dtm)\n",
    "    ax.set_xticks(np.arange(math.floor(first_dtm),last_dtm,t_ticks_step))\n",
    "    ax.set_xlabel('Time (days since $T_{admission}$)',fontsize=17)\n",
    "\n",
    "    ax.set_ylim(0, max_possible_PtoF)\n",
    "    ax.set_yticks(np.arange(0,max_possible_PtoF+50,PtoF_ticks_step))\n",
    "    ax.set_ylabel('$P/F$',fontsize=25)\n",
    "\n",
    "    ax2.set_ylim(0, max_possible_PEEP)\n",
    "    ax2.set_yticks(np.arange(0,max_possible_PEEP+1,PEEP_ticks_step))\n",
    "    ax2.set_ylabel('$PEEP$',fontsize=25, rotation=-90 , labelpad=20,color = 'blue')\n",
    "    ax2.tick_params(axis='y', color = 'blue', labelcolor = 'blue')  \n",
    "    ax2.spines['right'].set_color('blue')\n",
    "    ax2.spines['top'].set_color('0.85')\n",
    "\n",
    "    # To combine all three in one legend:\n",
    "    plot1, label1 = ax.get_legend_handles_labels()\n",
    "    plot2, label2 = ax2.get_legend_handles_labels()\n",
    "    if legend:\n",
    "        ax.legend(plot1+plot2, label1+label2, loc = 'upper right', prop={'size': 18})    \n",
    "        ax2.get_legend().remove() \n",
    "    else:\n",
    "        ax.get_legend().remove()\n",
    "        ax2.get_legend().remove()\n",
    "    plt.margins(x=0,y=0)\n",
    "    if save_fig:\n",
    "        plt.savefig('hadmID_{}_ARDS_graph.png'.format(hadm_ID), format='png',bbox_inches='tight')\n",
    "    plt.show()\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def PtoF_PEEP_Events_plot_pdfer(hadm_ID,Time_series_dict,trach_O2_dtm_dict, trach_proc_dtm_dict, \n",
    "                                filename = 'PtoF_chart',  directory ='/home/amir/Desktop/Project_ARDS/ARDS/',    \n",
    "                                t_ticks_step = 1, events_font_size = 20,PtoF_ticks_step = 50, PEEP_ticks_step = 5,\n",
    "                                max_possible_PtoF = 700, max_possible_PEEP = 25):\n",
    "    '''\n",
    "    comment out the infiltrate and CHF from pdf for if it has to be removed from pdf.\n",
    "    '''\n",
    "    \n",
    "    import matplotlib.pyplot as plt \n",
    "    import math\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) \n",
    "\n",
    "    time_series_df = Time_series_dict[hadm_ID].copy()\n",
    "    first_dtm = time_series_df['Days_since_T_admit'].min()\n",
    "    last_dtm  = time_series_df['Days_since_T_admit'].max()\n",
    "    trach_dtms             = [dtm for dtm in [trach_proc_dtm_dict[hadm_ID],trach_O2_dtm_dict[hadm_ID]] if pd.notnull(dtm)]\n",
    "    first_trach_record_dtm = min(trach_dtms) if len(trach_dtms)>0 else np.NaN\n",
    "    first_trach_record_day = (first_trach_record_dtm-time_series_df.CHARTTIME.min()).total_seconds()/60/60/24 if pd.notnull(first_trach_record_dtm) else np.NaN\n",
    "    \n",
    "    with PdfPages(directory + filename) as pdf:\n",
    "        plt.clf()    \n",
    "        fig,ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        plt.rcParams['xtick.labelsize']=16\n",
    "        plt.rcParams['ytick.labelsize']=16 \n",
    "        #_____________________________________________________________________________________________________________________________________________________\n",
    "        # P/F:\n",
    "        ax.axhspan(0, 100, color='r', alpha=0.15)\n",
    "        ax.axhspan(100, 200, color='r', alpha=0.07)\n",
    "        ax.axhspan(200, 300, color='r', alpha=0.02)\n",
    "        PtoF_df = time_series_df[pd.notnull(time_series_df.PtoF)]\n",
    "        PtoF_df.plot(x = 'Days_since_T_admit' , y = 'PtoF', linestyle = 'solid', marker = 'o', color = '0.15', markersize= 6, linewidth = 2, ax = ax)        \n",
    "        #_____________________________________________________________________________________________________________________________________________________ \n",
    "        # PEEP:\n",
    "        ax2 = ax.twinx()\n",
    "        PEEP_df = time_series_df[pd.notnull(time_series_df.PEEP)]\n",
    "        if len(PEEP_df)>0:\n",
    "            PEEP_df.plot(x = 'Days_since_T_admit' , y = 'PEEP', linestyle = 'solid', color = 'blue', linewidth = 1.5, ax = ax2, label = 'PEEP') \n",
    "        #_____________________________________________________________________________________________________________________________________________________\n",
    "        # Intubation/Extubation\n",
    "        times_markersize = 15\n",
    "\n",
    "        t_intub = time_series_df[time_series_df['Events']=='Intubated']['Days_since_T_admit'].values\n",
    "        t_extub = time_series_df[time_series_df['Events']=='Extubated']['Days_since_T_admit'].values\n",
    "\n",
    "        if (len(t_intub) > 0) & (len(t_extub) > 0):\n",
    "            ax.axvspan(t_intub, t_extub, color='black', alpha=0.05)\n",
    "            ax.axvline(x=t_intub, label = '', color = 'darkgreen',linewidth=2.0, linestyle = 'dashed')\n",
    "            ax.axvline(x=t_extub, label = '', color = 'darkgreen',linewidth=2.0, linestyle = 'dashed') \n",
    "            ax.plot(t_intub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "            ax.annotate('$T_{intubation}$',xy=(t_intub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "            ax.plot(t_extub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "            ax.annotate('$T_{extubation}$',xy=(t_extub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "\n",
    "        elif (len(t_intub) > 0) & (len(t_extub) == 0):\n",
    "            ax.axvspan(t_intub, last_dtm, color='black', alpha=0.05)\n",
    "            ax.axvline(x=t_intub, label = '', color = 'black',linewidth=2.0, linestyle = 'dotted')\n",
    "            ax.plot(t_intub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "            ax.annotate('$T_{intubation}$',xy=(t_intub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "            print('HADM_ID: {} was not extubated'.format(time_series_df[pd.notnull(time_series_df['HADM_ID'])]['HADM_ID'].tolist()[0]))        \n",
    "\n",
    "        elif (len(t_intub) == 0) & (len(t_extub) > 0):\n",
    "            ax.axvspan(0, t_extub, color='black', alpha=0.05)\n",
    "            ax.axvline(x=t_extub, label = '', color = 'black',linewidth=2.0, linestyle = 'dotted')\n",
    "            ax.plot(t_extub,max_possible_PtoF,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "            ax.annotate('$T_{extubation}$',xy=(t_extub, max_possible_PtoF+20),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "            print('HADM_ID: {} was intubated before arrival'.format(time_series_df[pd.notnull(time_series_df['HADM_ID'])]['HADM_ID'].tolist()[0]))\n",
    "        #     ____________________________________________________________________________________________________________________________________________________\n",
    "        # Tracheostomy:\n",
    "        if pd.notnull(first_trach_record_day):\n",
    "            ax.plot(first_trach_record_day,0,'o',color = 'purple',clip_on = False, markersize= times_markersize)\n",
    "            ax.annotate('$T^{0}_{trach}$',xy=(first_trach_record_day, 20),horizontalalignment='center', verticalalignment='bottom',\n",
    "                        fontsize = events_font_size+5 , annotation_clip=False, color = 'purple')\n",
    "        \n",
    "        #_____________________________________________________________________________________________________________________________________________________\n",
    "        # Discharge:\n",
    "        t_discharge = time_series_df[time_series_df['Events'].str.contains('Disposition',na=False)]['Days_since_T_admit'].values\n",
    "        disposition = time_series_df[time_series_df['Events'].str.contains('Disposition',na=False)]['Events'].values\n",
    "        ax.plot(t_discharge,0,'D',color = 'darkgreen',clip_on = False, markersize= times_markersize)\n",
    "        ax.annotate('$T_{discharge}$'+'({})'.format(disposition[0].split(': ')[1]),xy=(t_discharge, -60),horizontalalignment='center', verticalalignment='bottom',fontsize = events_font_size , annotation_clip=False, color = 'darkgreen')\n",
    "    \n",
    "        #____________________________________________________________________________________________________________________________________________________\n",
    "        # bilateral infiltrate in xrays:\n",
    "        t_pos_bilatOpac = time_series_df[time_series_df['Events']=='pos_bilatOpac']['Days_since_T_admit'].values\n",
    "        t_neg_bilatOpac = time_series_df[time_series_df['Events']=='neg_bilatOpac']['Days_since_T_admit'].values\n",
    "\n",
    "        label = True\n",
    "        for t in t_pos_bilatOpac:\n",
    "            ax.plot(t,max_possible_PtoF-10, clip_on = False, color = 'r', marker= '$\\u203C$', markersize= 16, linestyle='', label = 'Bilateral Opacities' if label else \"\")\n",
    "            label = False\n",
    "        label = True\n",
    "        \n",
    "\n",
    "        # CHF in xrays:\n",
    "        t_pos_chf = time_series_df[time_series_df['Events']=='pos_chf']['Days_since_T_admit'].values\n",
    "        t_neg_chf = time_series_df[time_series_df['Events']=='neg_chf']['Days_since_T_admit'].values\n",
    "\n",
    "        label = True\n",
    "        for t in t_pos_chf:\n",
    "            ax.plot(t,max_possible_PtoF+10, clip_on = False, color = 'r', linestyle='', label = 'Heart Failure/Fluid Overload' if label else \"\")\n",
    "            chf_y_delta = -70 if t in t_pos_bilatOpac else -32\n",
    "            imscatter(t, max_possible_PtoF+chf_y_delta, 'Icon_CHF.png', zoom=0.05, ax=ax)\n",
    "            label = False\n",
    "        \n",
    "        # Radio/Echo Reports with no evidence of either bilat opac and infilterates\n",
    "        label = True\n",
    "        for t in set(t_neg_bilatOpac.tolist()+t_neg_chf.tolist()+t_pos_bilatOpac.tolist()+t_pos_chf.tolist()):\n",
    "            ax.plot(t,max_possible_PtoF, clip_on = False, color = 'black', marker= '$☐$', markersize= 15, linestyle='', label = 'Radio/Echo Report' if label else \"\")\n",
    "            label = False \n",
    "        #_____________________________________________________________________________________________________________________________________________________\n",
    "        # Chart parameters:\n",
    "        ax.tick_params(axis=\"x\", bottom=True, top=True, labelbottom=True, labeltop=False)   \n",
    "        ax.set_xlim(math.floor(first_dtm), last_dtm)\n",
    "        ax.set_xticks(np.arange(math.floor(first_dtm),last_dtm,t_ticks_step))\n",
    "        ax.set_xlabel('Time (days since $T_{admission}$)',fontsize=17)\n",
    "\n",
    "        ax.set_ylim(0, max_possible_PtoF)\n",
    "        ax.set_yticks(np.arange(0,max_possible_PtoF+50,PtoF_ticks_step))\n",
    "        ax.set_ylabel('$P/F$',fontsize=25)\n",
    "\n",
    "        ax2.set_ylim(0, max_possible_PEEP)\n",
    "        ax2.set_yticks(np.arange(0,max_possible_PEEP+1,PEEP_ticks_step))\n",
    "        ax2.set_ylabel('$PEEP$',fontsize=25, rotation=-90 , labelpad=20,color = 'blue')\n",
    "        ax2.tick_params(axis='y', color = 'blue', labelcolor = 'blue')  \n",
    "        ax2.spines['right'].set_color('blue')\n",
    "        ax2.spines['top'].set_color('0.85')\n",
    "\n",
    "        # To combine all three in one legend:\n",
    "        plot1, label1 = ax.get_legend_handles_labels()\n",
    "        plot2, label2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(plot1+plot2, label1+label2, loc = 'upper right', prop={'size': 18})    \n",
    "        ax2.legend([], [])   \n",
    "        plt.margins(x=0,y=0)\n",
    "        pdf.savefig()\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------   \n",
    "def ARDS_detector(HADM_ID,Time_series_dict, trached_first_week_dict, o2_via_trach_first_week_dict,\n",
    "                  bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier, CXR_df,\n",
    "                  bilatOpac_window = 2, chf_window = 2, print_results = False):\n",
    "    '''\n",
    "    bilatOpac_window=2: Only fill missing bilatOpac values in the df, the closest one (either positive or negative) before or after. A positive/negative bilatOpac radiology applies from 2 days before to 2 days after the actual time of radiology. \n",
    "    chf_window =2     : A positive CHF radiology applies from 2 days before the actual time of radiology until THE END OF HOSPITALIZATION. \n",
    "    '''\n",
    "    import bisect\n",
    "    import re\n",
    "\n",
    "    \n",
    "    hadm_df = Time_series_dict[HADM_ID][['CHARTTIME','Days_since_T_admit','Events', 'FiO2','PaO2','PtoF','PEEP']].dropna(how = 'all').reset_index(drop=True).copy()    \n",
    "\n",
    "    hadm_df['Hypoxemic']   = np.where(pd.isnull(hadm_df['PtoF']),np.NaN,  np.where(hadm_df['PtoF']<=300,True,False))\n",
    "    hadm_df['PEEP_over_5'] = np.where(pd.isnull(hadm_df['PEEP']),np.NaN,  np.where(hadm_df['PEEP']>=5,True,False))\n",
    "    hadm_df['bilatOpac']   = np.where(hadm_df['Events']=='pos_bilatOpac',1, np.where(hadm_df['Events']=='neg_bilatOpac',0 ,np.NaN))\n",
    "    hadm_df['CHF']         = np.where(hadm_df['Events']=='pos_chf',      1, np.where(hadm_df['Events']=='neg_chf'      ,0 ,np.NaN))\n",
    "    hadm_df['bilatOpac_preped'] = hadm_df['bilatOpac'].copy()    \n",
    "    for index,row in hadm_df[hadm_df['bilatOpac_preped'].isnull()].iterrows():        \n",
    "        T_previous_bilatOpac = hadm_df[(hadm_df.Days_since_T_admit<=row['Days_since_T_admit']) & (pd.notnull(hadm_df['bilatOpac']))]['Days_since_T_admit'].max()\n",
    "        T_next_bilatOpac     = hadm_df[(hadm_df.Days_since_T_admit>row['Days_since_T_admit'])  & (pd.notnull(hadm_df['bilatOpac']))]['Days_since_T_admit'].min()\n",
    "        T_previous_bilatOpac = T_previous_bilatOpac if pd.notnull(T_previous_bilatOpac) else hadm_df.Days_since_T_admit.min()\n",
    "        T_next_bilatOpac     = T_next_bilatOpac     if pd.notnull(T_next_bilatOpac)     else hadm_df.Days_since_T_admit.max()\n",
    "        T_since_previous     = row['Days_since_T_admit']-T_previous_bilatOpac\n",
    "        T_until_next         = T_next_bilatOpac- row['Days_since_T_admit']\n",
    "       \n",
    "        if T_since_previous<=T_until_next:\n",
    "            if T_since_previous<=bilatOpac_window:\n",
    "                try:\n",
    "                    hadm_df.loc[index,'bilatOpac_preped'] = hadm_df[(hadm_df['Days_since_T_admit']==T_previous_bilatOpac)&(pd.notnull(hadm_df['bilatOpac']))]['bilatOpac'].tolist()[0]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        else:\n",
    "            if T_until_next<=bilatOpac_window:\n",
    "                try:\n",
    "                    hadm_df.loc[index,'bilatOpac_preped'] = hadm_df[(hadm_df['Days_since_T_admit']==T_next_bilatOpac)    &(pd.notnull(hadm_df['bilatOpac']))]['bilatOpac'].tolist()[0]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    \n",
    "    hadm_df['CHF_preped'] = hadm_df['CHF'].copy()\n",
    "    for time in hadm_df[hadm_df['CHF_preped']==1]['Days_since_T_admit'].tolist(): #When CHF starts, it never ends!\n",
    "        T_previous_neg_chf = hadm_df[(hadm_df.Days_since_T_admit<=time) & (hadm_df.Events=='neg_chf')]['Days_since_T_admit'].max()\n",
    "#         T_start_pos_chf    = max(T_previous_neg_chf,time-chf_window) if pd.notnull(T_previous_neg_chf) else time-chf_window  \n",
    "        T_start_pos_chf    =  time-chf_window        \n",
    "        hadm_df.loc[(hadm_df['Days_since_T_admit']>=T_start_pos_chf),'CHF_preped'] = 1\n",
    "    \n",
    "    hadm_df['ARDS']     = np.where((hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&(hadm_df['bilatOpac_preped']==1)&(hadm_df['CHF_preped']!=1),True, False)\n",
    "    T_ARDS_onset = hadm_df[hadm_df['ARDS']==True]['Days_since_T_admit'].min()\n",
    "    hypoxia_level      =  np.NaN if pd.isnull(T_ARDS_onset) else ['Severe','Moderate','Mild'][bisect.bisect_left([100,200,300], hadm_df['PtoF'].min())]\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Incorporating acuteness:\n",
    "    acuteness      = 1\n",
    "    trach_record   = max(trached_first_week_dict[HADM_ID],o2_via_trach_first_week_dict[HADM_ID])\n",
    "\n",
    "    if trach_record==1:\n",
    "        acuteness = 0\n",
    "        if pd.notnull(T_ARDS_onset):\n",
    "            print('Initial ARDS diagnosis for {} was reversed because in the first week trached = {} and o2_via_trach={}!'.format(HADM_ID,trached_first_week_dict[HADM_ID],o2_via_trach_first_week_dict[HADM_ID]))\n",
    "            T_ARDS_onset = np.NaN\n",
    "            hypoxia_level      = np.NaN\n",
    "    \n",
    "    ARDS_reversed_dueto_T_onset = 0\n",
    "    earliest_t_PEEP_over_5 = hadm_df[hadm_df['PEEP_over_5']==True]['Days_since_T_admit'].min()\n",
    "    if pd.notnull(T_ARDS_onset):  \n",
    "        if T_ARDS_onset-earliest_t_PEEP_over_5>7:\n",
    "            acuteness = 0\n",
    "            print('Initial ARDS diagnosis for {} was reversed because T_ARDS_onset-earliest_t_PEEP_over_5>7!'.format(HADM_ID))\n",
    "            T_ARDS_onset  = np.NaN\n",
    "            hypoxia_level = np.NaN\n",
    "            ARDS_reversed_dueto_T_onset = 1\n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Incorporating the lenght of intubation:\n",
    "    T_intub   = T_event_finder(hadm_df,'Intubated', default_T_if_no_event = pd.NaT)\n",
    "    T_extub   = T_event_finder(hadm_df,'Extubated', default_T_if_no_event = pd.NaT)\n",
    "    T_expired = T_event_finder(hadm_df,'Expired',   default_T_if_no_event = pd.NaT)\n",
    "    \n",
    "    vent_duration   = vent_duration_finder(HADM_ID,Time_series_dict)    \n",
    "    long_intubation = 1 if vent_duration>=2 else 0\n",
    "    \n",
    "    # Change long_intubation if patient dies in less than 2 days after intub or is palliatively extubated:\n",
    "    expired_in_2days_of_intub = 0\n",
    "    if pd.notnull(T_intub) & pd.notnull(T_expired):\n",
    "        intubation_to_expired_length = (T_expired-T_intub).total_seconds()/3600/24\n",
    "        if intubation_to_expired_length<=2:\n",
    "            expired_in_2days_of_intub = 1 \n",
    "        \n",
    "    \n",
    "    # Check if they died/hospiced within two days of extubation, which is assumed to indicate elective palliative extubation:\n",
    "    expired_in_2days_of_extub  = 0\n",
    "    hospiced_in_2days_of_extub = 0\n",
    "    if pd.notnull(T_extub):\n",
    "        T_discharge = hadm_df[hadm_df['Events'].str.contains('Disposition',na=False)]['CHARTTIME'].values\n",
    "        extubation_to_discharge_length = (T_discharge[0]-T_extub).total_seconds()/3600/24\n",
    "        if extubation_to_discharge_length<=2:\n",
    "            disposition = hadm_df[hadm_df['Events'].str.contains('Disposition',na=False)]['Events'].values\n",
    "            if re.search('expired',disposition[0].lower()) is not None:\n",
    "                expired_in_2days_of_extub  = 1\n",
    "            elif re.search('hospice',disposition[0].lower()) is not None:\n",
    "                hospiced_in_2days_of_extub = 1\n",
    "        \n",
    "    if pd.notnull(T_ARDS_onset):\n",
    "        if long_intubation==0:\n",
    "            if (expired_in_2days_of_intub==0) & (expired_in_2days_of_extub==0) & (hospiced_in_2days_of_extub==0):\n",
    "                print('Initial ARDS diagnosis for {} was reversed because the patient was intubated<48h!'.format(HADM_ID))\n",
    "                T_ARDS_onset  = np.NaN\n",
    "                hypoxia_level = np.NaN\n",
    "            else:\n",
    "                variable_names  = ['expired_in_2days_of_intub','expired_in_2days_of_extub','hospiced_in_2days_of_extub']\n",
    "                variable_values = [expired_in_2days_of_intub,expired_in_2days_of_extub,hospiced_in_2days_of_extub]\n",
    "                non_zeros =  [i for i, value in enumerate(variable_values) if value!=0]\n",
    "                non_zeros_variabls_string = ' and '.join([variable_names[i] for i in non_zeros])\n",
    "                print('Initial ARDS diagnosis for {} was kept even though intubated<48h because {} = 1!'.format(HADM_ID,non_zeros_variabls_string))\n",
    "\n",
    "        \n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # recording the reasons for ARDS diagnosis:\n",
    "    \n",
    "    Hypoxemic_while_peeped   = 1 if len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)])>0 else 0\n",
    "    bilatOpac_within_window  = 1 if len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&\n",
    "                                                (hadm_df['bilatOpac_preped']==1)])>0 else 0\n",
    "    bilatOpac_ever           = 1 if len(hadm_df[hadm_df['bilatOpac']==1])>0 else 0\n",
    "    \n",
    "    # Sometimes we have a hypoxemic, with bilatOpac and CHF but still ARDS, because CHF is detected after ARDS onset:180018\n",
    "    CHF_changing_ARDS        = 1 if (pd.isnull(T_ARDS_onset)) & (len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&\n",
    "                                                (hadm_df['bilatOpac_preped']==1)&(hadm_df['CHF_preped']==1)])>0) else 0\n",
    "    \n",
    "    CHF_with_or_after_ARDS_onset    = 1 if (pd.notnull(T_ARDS_onset)) & (len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&\n",
    "                                                (hadm_df['bilatOpac_preped']==1)&(hadm_df['CHF_preped']==1)])>0) else 0\n",
    "    \n",
    "    if print_results:\n",
    "        print((T_ARDS_onset,hypoxia_level, \n",
    "            acuteness, long_intubation, expired_in_2days_of_intub, \n",
    "            Hypoxemic_while_peeped, bilatOpac_ever, bilatOpac_within_window, \n",
    "            CHF_changing_ARDS,CHF_with_or_after_ARDS_onset))\n",
    "        display(hadm_df[hadm_df.ARDS==True])\n",
    "#         display(hadm_df.dropna(subset = ['Events','FiO2','PaO2','PtoF','PEEP','Hypoxemic','PEEP_over_5','bilatOpac','CHF','bilatOpac_preped','CHF_preped'],how='all',))\n",
    "        chest_radio_dtm_label_finder(HADM_ID, CXR_df, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier, print_results)\n",
    "    return (T_ARDS_onset,hypoxia_level, \n",
    "            trach_record, ARDS_reversed_dueto_T_onset, acuteness, \n",
    "            long_intubation, expired_in_2days_of_intub, expired_in_2days_of_extub, hospiced_in_2days_of_extub,\n",
    "            Hypoxemic_while_peeped, bilatOpac_ever, bilatOpac_within_window, \n",
    "            CHF_changing_ARDS,CHF_with_or_after_ARDS_onset,hadm_df)\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------   \n",
    "def old_ARDS_detector(HADM_ID,Time_series_dict, acuteness_dict, \n",
    "                  bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier, CXR_df,\n",
    "                  bilatOpac_window = 2, chf_window = 2, conn=connection, print_results = False):\n",
    "    '''\n",
    "    bilatOpac_window=2: Only fill missing bilatOpac values in the df, the closest one (either positive or negative) before or after. A positive/negative bilatOpac radiology applies from 2 days before to 2 days after the actual time of radiology. \n",
    "    chf_window =2     : A positive CHF radiology applies from 2 days before the actual time of radiology until THE END OF HOSPITALIZATION. \n",
    "    '''\n",
    "    import bisect\n",
    "\n",
    "    \n",
    "    hadm_df = Time_series_dict[HADM_ID][['CHARTTIME','Days_since_T_admit','Events', 'FiO2','PaO2','PtoF','PEEP']].dropna(how = 'all').reset_index(drop=True).copy()    \n",
    "\n",
    "    hadm_df['Hypoxemic']   = np.where(pd.isnull(hadm_df['PtoF']),np.NaN,  np.where(hadm_df['PtoF']<=300,True,False))\n",
    "    hadm_df['PEEP_over_5'] = np.where(pd.isnull(hadm_df['PEEP']),np.NaN,  np.where(hadm_df['PEEP']>=5,True,False))\n",
    "    hadm_df['bilatOpac']   = np.where(hadm_df['Events']=='pos_bilatOpac',1, np.where(hadm_df['Events']=='neg_bilatOpac',0 ,np.NaN))\n",
    "    hadm_df['CHF']         = np.where(hadm_df['Events']=='pos_chf',      1, np.where(hadm_df['Events']=='neg_chf'      ,0 ,np.NaN))\n",
    "    hadm_df['bilatOpac_preped'] = hadm_df['bilatOpac'].copy()    \n",
    "    for index,row in hadm_df[hadm_df['bilatOpac_preped'].isnull()].iterrows():        \n",
    "        T_previous_bilatOpac = hadm_df[(hadm_df.Days_since_T_admit<=row['Days_since_T_admit']) & (pd.notnull(hadm_df['bilatOpac']))]['Days_since_T_admit'].max()\n",
    "        T_next_bilatOpac     = hadm_df[(hadm_df.Days_since_T_admit>row['Days_since_T_admit'])  & (pd.notnull(hadm_df['bilatOpac']))]['Days_since_T_admit'].min()\n",
    "        T_previous_bilatOpac = T_previous_bilatOpac if pd.notnull(T_previous_bilatOpac) else hadm_df.Days_since_T_admit.min()\n",
    "        T_next_bilatOpac     = T_next_bilatOpac     if pd.notnull(T_next_bilatOpac)     else hadm_df.Days_since_T_admit.max()\n",
    "        T_since_previous     = row['Days_since_T_admit']-T_previous_bilatOpac\n",
    "        T_until_next         = T_next_bilatOpac- row['Days_since_T_admit']\n",
    "       \n",
    "        if T_since_previous<=T_until_next:\n",
    "            if T_since_previous<=bilatOpac_window:\n",
    "                try:\n",
    "                    hadm_df.loc[index,'bilatOpac_preped'] = hadm_df[(hadm_df['Days_since_T_admit']==T_previous_bilatOpac)&(pd.notnull(hadm_df['bilatOpac']))]['bilatOpac'].tolist()[0]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        else:\n",
    "            if T_until_next<=bilatOpac_window:\n",
    "                try:\n",
    "                    hadm_df.loc[index,'bilatOpac_preped'] = hadm_df[(hadm_df['Days_since_T_admit']==T_next_bilatOpac)    &(pd.notnull(hadm_df['bilatOpac']))]['bilatOpac'].tolist()[0]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    \n",
    "    hadm_df['CHF_preped'] = hadm_df['CHF'].copy()\n",
    "    for time in hadm_df[hadm_df['CHF_preped']==1]['Days_since_T_admit'].tolist(): #When CHF starts, it never ends!\n",
    "        T_previous_neg_chf = hadm_df[(hadm_df.Days_since_T_admit<=time) & (hadm_df.Events=='neg_chf')]['Days_since_T_admit'].max()\n",
    "        T_start_pos_chf    = max(T_previous_neg_chf,time-chf_window) if pd.notnull(T_previous_neg_chf) else time-chf_window        \n",
    "        hadm_df.loc[(hadm_df['Days_since_T_admit']>=T_start_pos_chf),'CHF_preped'] = 1\n",
    "    hadm_df['ARDS']     = np.where((hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&(hadm_df['bilatOpac_preped']==1)&(hadm_df['CHF_preped']!=1),True, False)\n",
    "    ARDS_diagnosis_dtm = hadm_df[hadm_df['ARDS']==True]['Days_since_T_admit'].min()\n",
    "    hypoxia_level      =  np.NaN if pd.isnull(ARDS_diagnosis_dtm) else ['Severe','Moderate','Mild'][bisect.bisect_left([100,200,300], hadm_df['PtoF'].min())]\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Incorporating acuteness:\n",
    "    acuteness = acuteness_dict[HADM_ID]\n",
    "    if acuteness==0:\n",
    "        if pd.notnull(ARDS_diagnosis_dtm):\n",
    "            print('Initial ARDS diagnosis for {} was reversed because the patient was trached!'.format(HADM_ID))\n",
    "            ARDS_diagnosis_dtm = np.NaN\n",
    "            hypoxia_level      = np.NaN\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Incorporating the lenght of intubation:\n",
    "    T_intub   = T_event_finder(hadm_df,'Intubated', default_T_if_no_event = pd.NaT)\n",
    "    T_expired = T_event_finder(hadm_df,'Expired',   default_T_if_no_event = pd.NaT)\n",
    "    vent_duration   = vent_duration_finder(HADM_ID,Time_series_dict)    \n",
    "    long_intubation = 1 if vent_duration>=2 else 0\n",
    "    \n",
    "    # Change long_intubation if patient dies in less than 2 days after intub:\n",
    "    if pd.notnull(T_intub) & pd.notnull(T_expired):\n",
    "        intubation_to_expired_length = (T_expired-T_intub).total_seconds()/3600/24\n",
    "        expired_on_vent_less_than_two_days = 1 if intubation_to_expired_length<=2 else 0\n",
    "    else:\n",
    "        expired_on_vent_less_than_two_days = 0\n",
    "    \n",
    "    if (long_intubation==0) & (expired_on_vent_less_than_two_days==0):\n",
    "        if pd.notnull(ARDS_diagnosis_dtm):\n",
    "            print('Initial ARDS diagnosis for {} was reversed because the patient was intubated<48h!'.format(HADM_ID))\n",
    "            ARDS_diagnosis_dtm = np.NaN\n",
    "            hypoxia_level      = np.NaN\n",
    "    elif (long_intubation==0) & (expired_on_vent_less_than_two_days==1):\n",
    "        if pd.notnull(ARDS_diagnosis_dtm):\n",
    "            print('Initial ARDS diagnosis for {} was kept even though intubated<48h because the patient expired under 48h!'.format(HADM_ID))\n",
    "        \n",
    "    #------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # recording the reasons for ARDS diagnosis:\n",
    "    \n",
    "    Hypoxemic_while_peeped   = 1 if len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)])>0 else 0\n",
    "    bilatOpac_within_window  = 1 if len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&\n",
    "                                                (hadm_df['bilatOpac_preped']==1)])>0 else 0\n",
    "    bilatOpac_ever           = 1 if len(hadm_df[hadm_df['bilatOpac']==1])>0 else 0\n",
    "    \n",
    "    # Sometimes we have a hypoxemic, with bilatOpac and CHF but still ARDS, because CHF is detected after ARDS onset:180018\n",
    "    CHF_changing_ARDS        = 1 if (pd.isnull(ARDS_diagnosis_dtm)) & (len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&\n",
    "                                                (hadm_df['bilatOpac_preped']==1)&(hadm_df['CHF_preped']==1)])>0) else 0\n",
    "    \n",
    "    CHF_with_or_after_ARDS_onset    = 1 if (pd.notnull(ARDS_diagnosis_dtm)) & (len(hadm_df[(hadm_df['Hypoxemic']==True)&(hadm_df['PEEP_over_5']==True)&\n",
    "                                                (hadm_df['bilatOpac_preped']==1)&(hadm_df['CHF_preped']==1)])>0) else 0\n",
    "    \n",
    "    if print_results:\n",
    "        print((ARDS_diagnosis_dtm,hypoxia_level, \n",
    "            acuteness, long_intubation, expired_on_vent_less_than_two_days, \n",
    "            Hypoxemic_while_peeped, bilatOpac_ever, bilatOpac_within_window, \n",
    "            CHF_changing_ARDS,CHF_with_or_after_ARDS_onset))\n",
    "        display(hadm_df[hadm_df.ARDS==True])\n",
    "        display(hadm_df.dropna(subset = ['Events','FiO2','PaO2','PtoF','PEEP','Hypoxemic','PEEP_over_5','bilatOpac','CHF','bilatOpac_preped','CHF_preped'],how='all',))\n",
    "        chest_radio_dtm_label_finder(HADM_ID, CXR_df, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier, print_results)\n",
    "    return (ARDS_diagnosis_dtm,hypoxia_level, \n",
    "            acuteness, long_intubation, expired_on_vent_less_than_two_days, \n",
    "            Hypoxemic_while_peeped, bilatOpac_ever, bilatOpac_within_window, \n",
    "            CHF_changing_ARDS,CHF_with_or_after_ARDS_onset,hadm_df)\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------   \n",
    "def older_ARDS_detector(hadm_ID,time_series_df, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier, bilatOpac_window = 2, chf_window = 2, conn=connection, print_results = False):\n",
    "    '''\n",
    "    bilatOpac_window=2: A positive bilatOpac radiology applies from 2 days before to 2 days after the actual time of radiology. \n",
    "    chf_window =2     : A positive CHF radiology applies from 2 days before the actual time of radiology until THE END OF HOSPITALIZATION. \n",
    "    '''\n",
    "    import bisect\n",
    "    result = time_series_df[['Days_since_T_admit','Events', 'FiO2','PaO2','PtoF','PEEP']].dropna(how = 'all')\n",
    "    result['Hypoxemic']   = np.where(pd.isnull(result['PtoF']),None,  np.where(result['PtoF']<=300,True,False))\n",
    "    result['PEEP_over_5'] = np.where(pd.isnull(result['PEEP']),None,  np.where(result['PEEP']>=5,True,False))\n",
    "    result['bilatOpac']   = np.where(result['Events']=='pos_bilatOpac',True, None)\n",
    "    result['CHF']         = np.where(result['Events']=='pos_chf',True, None)\n",
    "#     if len([i for i in result['CHF'].tolist() if i == True])>0:\n",
    "#         print('hadm_ID = {} has a positive CHF'.format(hadm_ID))\n",
    "    # This is for printing sentences when print_results= True\n",
    "    if print_results:\n",
    "        chest_radio_dtm_label_finder(hadm_ID, bilatOpac_classifier, radio_chf_classifier, echo_chf_classifier,conn, print_results)\n",
    "    \n",
    "    for time in result[result['bilatOpac']==True]['Days_since_T_admit'].tolist():\n",
    "        result.loc[(result['Days_since_T_admit']>=time-bilatOpac_window)&(result['Days_since_T_admit']<=time+bilatOpac_window),'bilatOpac'] = True\n",
    "        \n",
    "    result['ARDS'] = np.where((result['Hypoxemic']==True)&(result['PEEP_over_5']==True)&(result['bilatOpac']==True),True, False)\n",
    "    \n",
    "    # CHF: nulifies postive ARDS from 2 days before until the end of hospilazation \n",
    "    first_pos_chf = result[result['CHF']==True]['Days_since_T_admit'].min()\n",
    "    result.loc[(result['Days_since_T_admit']>=first_pos_chf-chf_window),'ARDS'] = False\n",
    "    \n",
    "    ARDS_diagnosis_dtm = result[result['ARDS']==True]['Days_since_T_admit'].min()\n",
    "    hypoxia_level =  np.NaN if pd.isnull(ARDS_diagnosis_dtm) else ['Severe','Moderate','Mild'][bisect.bisect_left([100,200,300], result['PtoF'].min())]\n",
    "    return (ARDS_diagnosis_dtm,hypoxia_level)\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def print_acuracy(CrossTab):\n",
    "    recall    = CrossTab.loc[1,1]/CrossTab.sum()[1]\n",
    "    precision = CrossTab.loc[1,1]/(CrossTab.loc[1,0]+CrossTab.loc[1,1])\n",
    "    specificity = CrossTab.loc[0,0]/CrossTab.sum()[0]\n",
    "    accuracy  = (CrossTab.loc[1,1]+CrossTab.loc[0,0])/CrossTab.sum().sum()\n",
    "    f_score   = 2*precision*recall/(precision+recall)\n",
    "    print('Accuracy :   {:.1f}%'.format(accuracy*100))\n",
    "    print('Recall   :   {:.1f}%'.format(recall*100))\n",
    "    print('Specificity: {:.1f}%'.format(specificity*100))\n",
    "    print('Precision:   {:.1f}%'.format(precision*100))\n",
    "    print('F-score  :   {:.1f}%'.format(f_score*100))\n",
    "    return accuracy,recall, specificity, precision,f_score\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def vent_duration_finder(HADM_ID, Time_series_dict):\n",
    "    '''\n",
    "    Return the vent duration in days\n",
    "    '''\n",
    "    HADM_time_series = Time_series_dict[HADM_ID].copy()\n",
    "    t_intub = HADM_time_series[HADM_time_series.Events=='Intubated']['CHARTTIME'].tolist()[0] if len(HADM_time_series[HADM_time_series.Events=='Intubated']['CHARTTIME'])>0 else pd.NaT\n",
    "    \n",
    "    if pd.notnull(t_intub):\n",
    "        t_extub_array = HADM_time_series[HADM_time_series.Events=='Extubated']['CHARTTIME']\n",
    "        if len(t_extub_array)==1:\n",
    "            t_extub = t_extub_array.tolist()[0]\n",
    "        elif len(t_extub_array)==0:\n",
    "            t_expired_array = HADM_time_series[HADM_time_series.Events=='Expired']['CHARTTIME']\n",
    "            if len(t_expired_array)>0:\n",
    "                t_extub = t_expired_array.tolist()[0]\n",
    "#                 print('Patient expired while intubated {}!'.format(HADM_ID))\n",
    "            else:\n",
    "                t_extub = HADM_time_series[HADM_time_series.Events=='Discharged']['CHARTTIME'].tolist()[0]\n",
    "#                 print('Patient discharged while still intubated {}!'.format(HADM_ID))\n",
    "        else:\n",
    "            print('Something weird happened, check {}!'.format(HADM_ID))   \n",
    "    else:\n",
    "        t_extub_array = HADM_time_series[HADM_time_series.Events=='Extubated']['CHARTTIME']\n",
    "        if len(t_extub_array)==0:\n",
    "            t_extub = pd.NaT\n",
    "        else:\n",
    "            print('Patient extubated with no record of intubation, extubation_record error {}!!!!!!'.format(HADM_ID))   \n",
    "            t_extub = pd.NaT\n",
    "    return  (t_extub-t_intub).total_seconds()/3600/24\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def T_event_finder(Time_series_df, Event_name, default_T_if_no_event = pd.NaT):\n",
    "    '''\n",
    "    This function finds the Time of the first occurance of an event.\n",
    "    '''\n",
    "    T_event_raw = Time_series_df[Time_series_df['Events']==Event_name]['CHARTTIME'].min()\n",
    "    T_event     = T_event_raw if pd.notnull(T_event_raw) else default_T_if_no_event\n",
    "    return T_event\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    import numpy as np\n",
    "    import scipy.stats\n",
    "    \n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    print('CI: {:.1f}%±{:.1f}%'.format(m*100,h*100))\n",
    "#     return m, m-h, m+h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
